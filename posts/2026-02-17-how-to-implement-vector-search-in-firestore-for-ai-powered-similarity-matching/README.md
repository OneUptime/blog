# How to Implement Vector Search in Firestore for AI-Powered Similarity Matching

Author: [nawazdhandala](https://www.github.com/nawazdhandala)

Tags: GCP, Firestore, Vector Search, AI, Embeddings, Similarity Search

Description: Learn how to store vector embeddings in Firestore and use its built-in vector search to find similar documents for recommendation engines, semantic search, and AI applications.

---

Vector search has become a core building block for AI-powered applications. Whether you are building semantic search, recommendation engines, or retrieval-augmented generation (RAG) pipelines, you need the ability to store vector embeddings and find similar ones quickly. Firestore now supports vector fields and nearest-neighbor search natively, which means you can add AI-powered similarity matching to your Firestore-backed application without spinning up a separate vector database.

## What Are Vector Embeddings?

Before diving into the implementation, a quick refresher. A vector embedding is a list of numbers (a float array) that represents a piece of content - text, images, audio, or anything else - in a high-dimensional space. Items that are semantically similar have embeddings that are close together in this space.

For example, the sentences "How do I reset my password?" and "I forgot my login credentials" would have similar embeddings even though they share few words. You generate these embeddings using models like OpenAI's text-embedding-ada-002, Google's textembedding-gecko, or any other embedding model.

## Storing Vector Embeddings in Firestore

Firestore supports a dedicated vector field type. You store embeddings as a FieldValue.vector() and Firestore handles the rest.

Here is how to store documents with embeddings:

```javascript
// Store a document with a vector embedding in Firestore
const { Firestore, FieldValue } = require('@google-cloud/firestore');

const db = new Firestore();

// Example: storing a product with its text embedding
// The embedding was generated by an embedding model from the product description
async function storeProductWithEmbedding(product, embedding) {
  await db.collection('products').doc(product.id).set({
    name: product.name,
    description: product.description,
    category: product.category,
    price: product.price,
    // Store the embedding as a Firestore vector field
    // The embedding array typically has 768 or 1536 dimensions
    descriptionEmbedding: FieldValue.vector(embedding)
  });
}

// Usage: generate embedding from the product description, then store it
const embedding = await generateEmbedding("Wireless noise-cancelling headphones with 30-hour battery life");
await storeProductWithEmbedding(
  { id: 'prod-001', name: 'QuietComfort Headphones', description: '...', category: 'audio', price: 299 },
  embedding
);
```

In Python with the Admin SDK:

```python
from google.cloud import firestore
from google.cloud.firestore_v1.vector import Vector

db = firestore.Client()

# Store a document with a vector embedding
# The Vector class wraps the float array for Firestore's vector type
def store_article_with_embedding(article_id, title, content, embedding):
    db.collection('articles').document(article_id).set({
        'title': title,
        'content': content,
        'published': True,
        # Wrap the embedding array in Vector() for proper storage
        'contentEmbedding': Vector(embedding)
    })
```

## Creating a Vector Index

Before you can run vector search queries, you need to create a vector index on the embedding field. This tells Firestore to build the data structures needed for efficient nearest-neighbor search.

You can create the index using the Firebase CLI or the Google Cloud Console:

```bash
# Create a vector index on the descriptionEmbedding field
# The dimension must match your embedding model's output dimension
gcloud firestore indexes composite create \
  --collection-group=products \
  --query-scope=COLLECTION \
  --field-config="vector-config={dimension:768,flat},field-path=descriptionEmbedding"
```

The dimension parameter must match the number of dimensions in your embedding model's output. Common values are 768 (for models like textembedding-gecko) and 1536 (for text-embedding-ada-002).

## Running Vector Search Queries

Once the index is built, you can find similar documents using the findNearest method:

```javascript
// Find products similar to a search query using vector search
const { Firestore, FieldValue } = require('@google-cloud/firestore');

const db = new Firestore();

async function searchSimilarProducts(queryText, limit = 10) {
  // Step 1: Generate an embedding for the search query
  const queryEmbedding = await generateEmbedding(queryText);

  // Step 2: Run vector search to find the nearest neighbors
  const results = await db.collection('products')
    .findNearest({
      vectorField: 'descriptionEmbedding',  // The field containing embeddings
      queryVector: FieldValue.vector(queryEmbedding),  // The query embedding
      limit: limit,  // Return top N results
      distanceMeasure: 'COSINE'  // Similarity metric
    })
    .get();

  // Step 3: Process results
  const products = [];
  results.forEach(doc => {
    products.push({
      id: doc.id,
      ...doc.data(),
      // The distance/similarity score is available on the result
    });
  });

  return products;
}

// Example: find products similar to a user's search
const results = await searchSimilarProducts("comfortable headphones for long flights");
```

### Python Example

```python
from google.cloud import firestore
from google.cloud.firestore_v1.vector import Vector
from google.cloud.firestore_v1.base_vector_query import DistanceMeasure

db = firestore.Client()

def find_similar_articles(query_text, limit=5):
    # Generate embedding for the query
    query_embedding = generate_embedding(query_text)

    # Run vector nearest-neighbor search
    # COSINE distance is the most common choice for text embeddings
    results = (
        db.collection('articles')
        .find_nearest(
            vector_field='contentEmbedding',
            query_vector=Vector(query_embedding),
            distance_measure=DistanceMeasure.COSINE,
            limit=limit,
        )
        .get()
    )

    articles = []
    for doc in results:
        data = doc.to_dict()
        articles.append({
            'id': doc.id,
            'title': data['title'],
            'content': data['content'][:200]  # Preview
        })

    return articles
```

## Combining Vector Search with Filters

One of the advantages of vector search in Firestore over dedicated vector databases is that you can combine it with Firestore's existing query filters. This lets you do filtered similarity search:

```javascript
// Find similar products but only within a specific category and price range
async function searchProductsInCategory(queryText, category, maxPrice) {
  const queryEmbedding = await generateEmbedding(queryText);

  // Combine where() filters with findNearest()
  // Firestore applies the filters first, then searches within the filtered set
  const results = await db.collection('products')
    .where('category', '==', category)
    .where('price', '<=', maxPrice)
    .findNearest({
      vectorField: 'descriptionEmbedding',
      queryVector: FieldValue.vector(queryEmbedding),
      limit: 10,
      distanceMeasure: 'COSINE'
    })
    .get();

  return results.docs.map(doc => ({ id: doc.id, ...doc.data() }));
}

// Search for headphones under $200 that match "wireless noise cancelling"
const results = await searchProductsInCategory(
  "wireless noise cancelling",
  "audio",
  200
);
```

## Building a Semantic Search Feature

Here is a more complete example of building a semantic search feature for a knowledge base:

```javascript
// Complete semantic search implementation for a knowledge base
const { Firestore, FieldValue } = require('@google-cloud/firestore');
const { VertexAI } = require('@google-cloud/vertexai');

const db = new Firestore();

// Initialize the Vertex AI embedding model
const vertexai = new VertexAI({ project: 'my-project', location: 'us-central1' });
const embeddingModel = vertexai.getGenerativeModel({ model: 'textembedding-gecko@003' });

// Generate an embedding using Vertex AI
async function generateEmbedding(text) {
  const result = await embeddingModel.embedContent(text);
  return result.embedding.values;
}

// Index a new knowledge base article
async function indexArticle(articleId, title, content, tags) {
  // Combine title and content for a richer embedding
  const textToEmbed = `${title}. ${content}`;
  const embedding = await generateEmbedding(textToEmbed);

  await db.collection('knowledge_base').doc(articleId).set({
    title: title,
    content: content,
    tags: tags,
    updatedAt: FieldValue.serverTimestamp(),
    embedding: FieldValue.vector(embedding)
  });
}

// Search the knowledge base semantically
async function searchKnowledgeBase(query, options = {}) {
  const queryEmbedding = await generateEmbedding(query);
  const limit = options.limit || 5;

  let queryRef = db.collection('knowledge_base');

  // Apply optional tag filter
  if (options.tag) {
    queryRef = queryRef.where('tags', 'array-contains', options.tag);
  }

  const results = await queryRef
    .findNearest({
      vectorField: 'embedding',
      queryVector: FieldValue.vector(queryEmbedding),
      limit: limit,
      distanceMeasure: 'COSINE',
      distanceResultField: 'searchDistance'  // Include distance in results
    })
    .get();

  return results.docs.map(doc => {
    const data = doc.data();
    return {
      id: doc.id,
      title: data.title,
      content: data.content,
      distance: data.searchDistance,  // Lower distance = more similar
      tags: data.tags
    };
  });
}
```

## Building a RAG Pipeline with Firestore

Vector search in Firestore is a natural fit for retrieval-augmented generation. You retrieve relevant context using vector search, then pass it to a language model:

```python
from google.cloud import firestore
from google.cloud.firestore_v1.vector import Vector
from google.cloud.firestore_v1.base_vector_query import DistanceMeasure
import vertexai
from vertexai.generative_models import GenerativeModel

db = firestore.Client()

def answer_question_with_context(question):
    # Step 1: Find relevant documents using vector search
    query_embedding = generate_embedding(question)

    relevant_docs = (
        db.collection('knowledge_base')
        .find_nearest(
            vector_field='embedding',
            query_vector=Vector(query_embedding),
            distance_measure=DistanceMeasure.COSINE,
            limit=3,
        )
        .get()
    )

    # Step 2: Build context from retrieved documents
    context_parts = []
    for doc in relevant_docs:
        data = doc.to_dict()
        context_parts.append(f"Title: {data['title']}\nContent: {data['content']}")

    context = "\n\n---\n\n".join(context_parts)

    # Step 3: Pass context + question to the language model
    model = GenerativeModel("gemini-pro")
    prompt = f"""Based on the following context, answer the user's question.

Context:
{context}

Question: {question}

Answer:"""

    response = model.generate_content(prompt)
    return response.text
```

## Distance Measures

Firestore supports three distance measures for vector search:

- COSINE: Best for text embeddings. Measures the angle between vectors, ignoring magnitude. Most commonly used.
- EUCLIDEAN: Measures straight-line distance. Useful when magnitude matters.
- DOT_PRODUCT: Measures the dot product. Fast and works well when vectors are normalized.

For most text-based applications, COSINE is the right choice.

## Wrapping Up

Vector search in Firestore lets you add AI-powered similarity features without introducing a separate vector database into your stack. You store embeddings alongside your regular document data, query them with familiar Firestore patterns, and combine vector search with standard filters. For applications already using Firestore, this is the most straightforward path to semantic search, recommendations, and RAG pipelines. The key is to make sure your embedding dimensions match your index configuration and to choose the right distance measure for your use case.
