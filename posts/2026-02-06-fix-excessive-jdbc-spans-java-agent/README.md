# How to Fix OpenTelemetry Java Agent Producing Excessive JDBC Spans That Overwhelm Your Tracing Backend

Author: [nawazdhandala](https://www.github.com/nawazdhandala)

Tags: OpenTelemetry, Java, JDBC, Performance

Description: Reduce the volume of JDBC spans generated by the OpenTelemetry Java agent to prevent overwhelming your tracing backend.

The OpenTelemetry Java agent instruments JDBC calls by default, creating a span for every SQL query. In applications that make dozens or hundreds of database queries per request (especially with ORMs like Hibernate), this generates thousands of spans per second, overwhelming your tracing backend and dramatically increasing costs.

## The Problem

A single API request that loads a user with their orders and order items might generate:

```
GET /api/users/123                               [========================] 150ms
  SELECT * FROM users WHERE id = ?               [=]  3ms
  SELECT * FROM user_preferences WHERE user_id=? [=]  2ms
  SELECT * FROM orders WHERE user_id = ?         [=]  5ms
  SELECT * FROM order_items WHERE order_id = ?   [=]  3ms  (x10 orders)
  SELECT * FROM products WHERE id = ?            [=]  2ms  (x30 items)
  SELECT * FROM categories WHERE id = ?          [=]  1ms  (x10 categories)
```

That is 55+ JDBC spans for a single request. At 100 requests per second, you generate 5,500 JDBC spans per second on top of your other instrumentation.

## Fix 1: Disable JDBC Instrumentation

If you do not need per-query visibility:

```bash
java -javaagent:opentelemetry-javaagent.jar \
     -Dotel.instrumentation.jdbc.enabled=false \
     -jar myapp.jar
```

You lose database query-level spans but still get HTTP, Spring, and other spans.

## Fix 2: Disable the JDBC Datasource Instrumentation

The agent instruments both the JDBC driver and the datasource (connection pool). Disable the datasource instrumentation to reduce noise:

```bash
java -javaagent:opentelemetry-javaagent.jar \
     -Dotel.instrumentation.jdbc-datasource.enabled=false \
     -jar myapp.jar
```

## Fix 3: Use Statement Sanitization to Reduce Cardinality

By default, the agent captures the full SQL statement. Sanitization replaces literal values with `?`:

```bash
# This is usually on by default, but verify
java -javaagent:opentelemetry-javaagent.jar \
     -Dotel.instrumentation.jdbc.statement-sanitizer.enabled=true \
     -jar myapp.jar
```

This does not reduce span count, but it reduces the cardinality of span attributes and the storage needed per span.

## Fix 4: Suppress Short Queries with a Custom Sampler

Create a sampler that drops spans shorter than a threshold:

```java
// Custom sampler that filters out fast DB queries
public class DatabaseQuerySampler implements Sampler {
    private final Sampler delegate;

    public DatabaseQuerySampler(Sampler delegate) {
        this.delegate = delegate;
    }

    @Override
    public SamplingResult shouldSample(
            Context parentContext,
            String traceId,
            String name,
            SpanKind spanKind,
            Attributes attributes,
            List<LinkData> links) {

        // Always sample non-DB spans
        String dbSystem = attributes.get(AttributeKey.stringKey("db.system"));
        if (dbSystem == null) {
            return delegate.shouldSample(parentContext, traceId, name, spanKind, attributes, links);
        }

        // For DB spans, delegate to the parent sampler
        return delegate.shouldSample(parentContext, traceId, name, spanKind, attributes, links);
    }

    @Override
    public String getDescription() {
        return "DatabaseQuerySampler";
    }
}
```

## Fix 5: Use Sampling to Reduce Overall Volume

Sample a percentage of traces, which proportionally reduces JDBC spans:

```bash
java -javaagent:opentelemetry-javaagent.jar \
     -Dotel.traces.sampler=parentbased_traceidratio \
     -Dotel.traces.sampler.arg=0.1 \
     -jar myapp.jar
```

## Fix 6: Filter at the Collector

Use the Collector's filter processor to drop JDBC spans that are under a duration threshold:

```yaml
processors:
  filter:
    spans:
      exclude:
        match_type: regexp
        attributes:
          - key: db.system
            value: ".*"
        span_names:
          - ".*"
        # Only keep DB spans longer than 100ms

  # Alternative: use tail_sampling to keep only slow queries
  tail_sampling:
    decision_wait: 10s
    policies:
      - name: keep-slow-db-queries
        type: latency
        latency:
          threshold_ms: 100
      - name: keep-errors
        type: status_code
        status_code:
          status_codes: [ERROR]
      - name: sample-rest
        type: probabilistic
        probabilistic:
          sampling_percentage: 10

service:
  pipelines:
    traces:
      receivers: [otlp]
      processors: [tail_sampling, batch]
      exporters: [otlp]
```

## Fix 7: Use Hibernate-Level Instrumentation Instead

Instead of per-query JDBC spans, use Hibernate instrumentation which creates spans at the session/transaction level:

```bash
# Enable Hibernate instrumentation
-Dotel.instrumentation.hibernate.enabled=true

# Disable raw JDBC instrumentation
-Dotel.instrumentation.jdbc.enabled=false
```

Hibernate spans group related queries under a single operation, reducing span count while maintaining useful visibility.

## Estimating Span Volume

Before deploying, estimate your JDBC span volume:

```
JDBC spans/sec = requests/sec x queries/request
Cost = JDBC spans/sec x 86400 x bytes/span x $/byte

Example:
100 req/sec x 50 queries/req = 5,000 JDBC spans/sec
5,000 x 86,400 = 432 million spans/day
```

At most tracing backends, 432 million spans/day is expensive. Sampling at 10% brings it to 43 million, which is more manageable.

The key is to be intentional about JDBC instrumentation. Not every query needs its own span. Use sampling, filtering, or higher-level instrumentation to keep the signal-to-noise ratio high.
