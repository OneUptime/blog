# How to Use Ansible to Configure Multipath Storage

Author: [nawazdhandala](https://www.github.com/nawazdhandala)

Tags: Ansible, Multipath, Storage, Linux

Description: A practical guide to configuring DM-Multipath storage on Linux servers using Ansible for reliable SAN connectivity.

---

If you have ever worked with SAN-attached storage in a data center, you know that multipath I/O is not optional. It is a requirement. When a server connects to a storage array through multiple physical paths (dual HBAs, redundant fabric switches), the operating system sees the same LUN presented multiple times. Without multipath, the OS treats each path as a separate disk, which leads to data corruption, confused applications, and a very bad day.

Device Mapper Multipath (DM-Multipath) solves this by aggregating the redundant paths into a single block device. Configuring it by hand across a fleet of servers is tedious and error-prone. Ansible makes this much more manageable.

## Prerequisites

Before you start, make sure your servers have:

- Physical or virtual connectivity to a SAN (Fibre Channel or iSCSI)
- At least two paths to the storage array
- RHEL/CentOS 7+ or Ubuntu 18.04+ (the examples here target RHEL-family systems primarily)

## Installing Multipath Packages

The first step is getting the right packages installed on all your storage-connected hosts.

```yaml
# install-multipath.yml - Install device-mapper-multipath and dependencies
---
- name: Install and enable multipath
  hosts: san_connected
  become: true

  tasks:
    # Install the multipath tools package
    - name: Install device-mapper-multipath
      ansible.builtin.yum:
        name:
          - device-mapper-multipath
          - device-mapper-multipath-libs
        state: present
      when: ansible_os_family == "RedHat"

    # For Debian/Ubuntu systems
    - name: Install multipath-tools (Debian)
      ansible.builtin.apt:
        name:
          - multipath-tools
          - multipath-tools-boot
        state: present
        update_cache: true
      when: ansible_os_family == "Debian"

    # Generate the initial configuration file if it does not exist
    - name: Check if multipath.conf exists
      ansible.builtin.stat:
        path: /etc/multipath.conf
      register: mp_conf

    - name: Generate default multipath config
      ansible.builtin.command:
        cmd: mpathconf --enable
      when:
        - not mp_conf.stat.exists
        - ansible_os_family == "RedHat"
```

## Deploying the Multipath Configuration

The heart of multipath setup is the `/etc/multipath.conf` file. This controls how paths are grouped, which failover policy to use, and how specific storage arrays are handled.

```yaml
# configure-multipath.yml - Deploy multipath.conf with proper settings
---
- name: Configure DM-Multipath
  hosts: san_connected
  become: true

  vars:
    # Polling interval in seconds for path checking
    multipath_polling_interval: 5
    # Default path grouping policy
    multipath_path_grouping: multibus
    # Default failback behavior (immediate or manual)
    multipath_failback: immediate
    # Blacklist local disks so multipath ignores them
    blacklist_devices:
      - devnode: "^sd[a]$"
      - devnode: "^vd[a-z]"
      - devnode: "^nvme"

  tasks:
    # Deploy the main multipath.conf from template
    - name: Deploy multipath.conf
      ansible.builtin.template:
        src: multipath.conf.j2
        dest: /etc/multipath.conf
        owner: root
        group: root
        mode: '0644'
        backup: true
      notify: restart multipathd

    # Make sure the service is enabled and running
    - name: Enable and start multipathd
      ansible.builtin.systemd:
        name: multipathd
        state: started
        enabled: true

  handlers:
    - name: restart multipathd
      ansible.builtin.systemd:
        name: multipathd
        state: restarted
```

Here is the Jinja2 template for the configuration file:

```jinja2
# multipath.conf.j2 - Generated by Ansible, do not edit manually
# Managed on: {{ ansible_date_time.iso8601 }}

defaults {
    polling_interval     {{ multipath_polling_interval }}
    path_grouping_policy {{ multipath_path_grouping }}
    failback             {{ multipath_failback }}
    no_path_retry        5
    rr_min_io_rq         1
    path_checker         tur
    user_friendly_names  yes
    find_multipaths      yes
}

# Blacklist local devices that should not be managed by multipath
blacklist {
{% for dev in blacklist_devices %}
    devnode "{{ dev.devnode }}"
{% endfor %}
    # Blacklist all partitions
    devnode "^(ram|raw|loop|fd|md|dm-|sr|scd|st)[0-9]*"
}

# Device-specific overrides for common storage arrays
devices {
    # NetApp FAS/AFF arrays
    device {
        vendor  "NETAPP"
        product "LUN.*"
        path_grouping_policy group_by_prio
        path_selector "round-robin 0"
        prio alua
        failback immediate
        rr_weight uniform
        no_path_retry queue
    }

    # Dell EMC PowerStore / Unity
    device {
        vendor  "DGC"
        product ".*"
        path_grouping_policy group_by_prio
        path_selector "round-robin 0"
        prio alua
        failback immediate
    }
}

# Explicit multipath definitions for specific LUNs
multipaths {
{% if multipath_maps is defined %}
{% for mp in multipath_maps %}
    multipath {
        wwid    {{ mp.wwid }}
        alias   {{ mp.alias }}
{% if mp.path_grouping is defined %}
        path_grouping_policy {{ mp.path_grouping }}
{% endif %}
    }
{% endfor %}
{% endif %}
}
```

## Discovering and Mapping Paths

After deploying the configuration, you need to scan for new devices and build the multipath maps. This playbook handles path discovery:

```yaml
# discover-paths.yml - Scan for SAN devices and build multipath maps
---
- name: Discover and map multipath devices
  hosts: san_connected
  become: true

  tasks:
    # Rescan the SCSI bus to find new LUNs
    - name: Rescan SCSI hosts
      ansible.builtin.shell:
        cmd: |
          for host in /sys/class/scsi_host/host*; do
            echo "- - -" > ${host}/scan
          done
      changed_when: true

    # Wait a few seconds for the OS to detect new devices
    - name: Wait for device discovery
      ansible.builtin.pause:
        seconds: 10

    # Reconfigure multipath to pick up new paths
    - name: Reconfigure multipath
      ansible.builtin.command:
        cmd: multipath -r
      changed_when: true

    # Collect the current multipath topology
    - name: Get multipath topology
      ansible.builtin.command:
        cmd: multipath -ll
      register: multipath_topology
      changed_when: false

    - name: Display multipath topology
      ansible.builtin.debug:
        var: multipath_topology.stdout_lines

    # Count the paths per device
    - name: Check path count per multipath device
      ansible.builtin.shell:
        cmd: "multipath -ll | grep -c 'active ready'"
      register: active_paths
      changed_when: false
      failed_when: false

    - name: Report active path count
      ansible.builtin.debug:
        msg: "Total active paths on {{ inventory_hostname }}: {{ active_paths.stdout }}"
```

## Monitoring Multipath Health

Path failures happen. A switch goes down, an HBA dies, a cable gets unplugged. You need to know about it fast.

```yaml
# monitor-multipath.yml - Check multipath health and alert on degraded paths
---
- name: Monitor multipath health
  hosts: san_connected
  become: true

  vars:
    # Minimum expected paths per device
    min_paths_per_device: 2

  tasks:
    # Get the status of all multipath devices
    - name: Get multipath status
      ansible.builtin.command:
        cmd: multipathd show paths format "%d %s %t %T"
      register: path_status
      changed_when: false

    # Check for any failed or faulty paths
    - name: Check for faulty paths
      ansible.builtin.shell:
        cmd: multipathd show paths format "%d %s %t %T" | grep -i "faulty" || true
      register: faulty_paths
      changed_when: false

    # Alert if there are faulty paths
    - name: Alert on faulty paths
      ansible.builtin.debug:
        msg: "WARNING: Faulty paths detected on {{ inventory_hostname }}: {{ faulty_paths.stdout_lines }}"
      when: faulty_paths.stdout | length > 0

    # Verify each device has the minimum number of active paths
    - name: Get path count per device
      ansible.builtin.shell:
        cmd: |
          multipath -ll | grep "^mpath" | while read line; do
            dev=$(echo "$line" | awk '{print $1}')
            count=$(multipath -ll "$dev" | grep -c "active ready" || echo 0)
            echo "${dev}:${count}"
          done
      register: path_counts
      changed_when: false

    - name: Display path counts
      ansible.builtin.debug:
        var: path_counts.stdout_lines
```

## Multipath Architecture Overview

Here is a diagram showing how multipath fits into the storage stack:

```mermaid
flowchart TD
    SA[Storage Array] --> |Path 1| SW1[SAN Switch A]
    SA --> |Path 2| SW2[SAN Switch B]
    SW1 --> HBA1[HBA Port 1]
    SW2 --> HBA2[HBA Port 2]
    HBA1 --> SCSI1[/dev/sdb]
    HBA2 --> SCSI2[/dev/sdc]
    SCSI1 --> DM[DM-Multipath]
    SCSI2 --> DM
    DM --> MPATH[/dev/mapper/mpath0]
    MPATH --> FS[Filesystem / LVM]
    FS --> APP[Application]
```

## Handling Multipath on iSCSI Connections

If your SAN connectivity is iSCSI rather than Fibre Channel, you need additional configuration for the iSCSI initiator:

```yaml
# iscsi-multipath.yml - Configure iSCSI with multipath
---
- name: Configure iSCSI multipath
  hosts: iscsi_hosts
  become: true

  vars:
    iscsi_targets:
      - portal: "10.0.1.100:3260"
        target: "iqn.2024-01.com.storage:array01"
      - portal: "10.0.2.100:3260"
        target: "iqn.2024-01.com.storage:array01"

  tasks:
    # Install iSCSI initiator
    - name: Install iscsi-initiator-utils
      ansible.builtin.yum:
        name: iscsi-initiator-utils
        state: present

    # Set the initiator name
    - name: Configure initiator name
      ansible.builtin.template:
        src: initiatorname.iscsi.j2
        dest: /etc/iscsi/initiatorname.iscsi
        mode: '0600'
      notify: restart iscsid

    # Discover and login to each target portal
    - name: Discover iSCSI targets
      community.general.open_iscsi:
        portal: "{{ item.portal }}"
        target: "{{ item.target }}"
        login: true
        auto_node_startup: true
        discover: true
      loop: "{{ iscsi_targets }}"

    # Reconfigure multipath after iSCSI login
    - name: Reconfigure multipath for iSCSI
      ansible.builtin.command:
        cmd: multipath -r
      changed_when: true

  handlers:
    - name: restart iscsid
      ansible.builtin.systemd:
        name: iscsid
        state: restarted
```

## Tips from the Trenches

Here are some things that have saved me many hours of debugging in production:

1. Always blacklist your boot disk. If multipath grabs your root filesystem disk, you will have a very exciting boot experience (and not in a good way).

2. Use `find_multipaths yes` in defaults. This prevents multipath from claiming single-path devices, which is almost always what you want.

3. Test failover before going to production. Pull a cable (or simulate it) and verify that I/O continues on the remaining path without interruption.

4. The `user_friendly_names yes` setting gives you names like `mpath0` instead of long WWID strings. It is much easier to work with, but be aware that the mapping can change if devices appear in a different order after reboot. For critical production LUNs, use explicit alias mappings in the `multipaths` section.

5. Keep your multipath.conf in version control and deploy it through Ansible. Manual edits to this file across dozens of servers will lead to inconsistencies that are painful to debug.

Multipath is one of those things that is boring when it works and terrifying when it does not. Getting it right with Ansible means you can be confident every server in your fleet has the same, tested configuration.
