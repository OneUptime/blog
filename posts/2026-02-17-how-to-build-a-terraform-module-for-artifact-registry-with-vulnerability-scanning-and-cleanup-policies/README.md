# How to Build a Terraform Module for Artifact Registry with Vulnerability Scanning and Cleanup Policies

Author: [nawazdhandala](https://www.github.com/nawazdhandala)

Tags: GCP, Terraform, Artifact Registry, Container Security, Google Cloud Platform

Description: Build a Terraform module for Google Artifact Registry that includes Docker repository creation, automated vulnerability scanning, cleanup policies for old images, and IAM access controls.

---

Container registries tend to become dumping grounds. Teams push images constantly but rarely clean up. Before long, you have thousands of images, many with known vulnerabilities, eating up storage and creating a security risk. Artifact Registry on GCP gives you vulnerability scanning and cleanup policies to keep things under control, and managing it all with Terraform means it is consistent across projects.

Here is how to build a reusable module for it.

## Module Structure

```
modules/artifact-registry/
  main.tf
  variables.tf
  outputs.tf
  cleanup.tf
  scanning.tf
  iam.tf
```

## Variables

Define the inputs that make the module flexible:

```hcl
# variables.tf - Inputs for the Artifact Registry module

variable "project_id" {
  description = "GCP project ID"
  type        = string
}

variable "location" {
  description = "Region for the repository"
  type        = string
  default     = "us-central1"
}

variable "repository_id" {
  description = "ID for the Artifact Registry repository"
  type        = string
}

variable "description" {
  description = "Repository description"
  type        = string
  default     = ""
}

variable "format" {
  description = "Repository format (DOCKER, MAVEN, NPM, PYTHON, APT, YUM, GO)"
  type        = string
  default     = "DOCKER"
}

variable "immutable_tags" {
  description = "Prevent tag mutation (overwriting existing tags)"
  type        = bool
  default     = false
}

variable "cleanup_policy_dry_run" {
  description = "Run cleanup policies in dry-run mode (log only, do not delete)"
  type        = bool
  default     = true
}

variable "vulnerability_scanning_enabled" {
  description = "Enable automatic vulnerability scanning on push"
  type        = bool
  default     = true
}

variable "readers" {
  description = "List of IAM members with read access"
  type        = list(string)
  default     = []
}

variable "writers" {
  description = "List of IAM members with push access"
  type        = list(string)
  default     = []
}

variable "keep_tagged_days" {
  description = "Number of days to keep tagged images"
  type        = number
  default     = 90
}

variable "keep_untagged_days" {
  description = "Number of days to keep untagged images"
  type        = number
  default     = 7
}

variable "keep_minimum_versions" {
  description = "Minimum number of versions to keep per image"
  type        = number
  default     = 5
}

variable "labels" {
  description = "Labels to apply to the repository"
  type        = map(string)
  default     = {}
}
```

## Creating the Repository

The main repository resource with Docker configuration:

```hcl
# main.tf - Artifact Registry repository

resource "google_artifact_registry_repository" "repo" {
  project       = var.project_id
  location      = var.location
  repository_id = var.repository_id
  description   = var.description
  format        = var.format

  labels = var.labels

  # Docker-specific configuration
  dynamic "docker_config" {
    for_each = var.format == "DOCKER" ? [1] : []
    content {
      # Prevent overwriting existing tags when set to true
      # This ensures that "v1.2.3" always points to the same image
      immutable_tags = var.immutable_tags
    }
  }

  # Cleanup policies determine how old images are handled
  cleanup_policy_dry_run = var.cleanup_policy_dry_run
}
```

## Cleanup Policies

Cleanup policies automatically delete old images based on conditions you define. This is where the real value is - without cleanup, registries grow indefinitely:

```hcl
# cleanup.tf - Image cleanup policies

# Delete untagged images older than the configured threshold
resource "google_artifact_registry_repository_cleanup_policy" "delete_untagged" {
  project    = var.project_id
  location   = var.location
  repository = google_artifact_registry_repository.repo.name
  policy_id  = "delete-untagged"

  action = "DELETE"

  condition {
    tag_state  = "UNTAGGED"
    older_than = "${var.keep_untagged_days * 24 * 60 * 60}s"
  }
}

# Delete old tagged images beyond retention period
resource "google_artifact_registry_repository_cleanup_policy" "delete_old_tagged" {
  project    = var.project_id
  location   = var.location
  repository = google_artifact_registry_repository.repo.name
  policy_id  = "delete-old-tagged"

  action = "DELETE"

  condition {
    tag_state  = "TAGGED"
    older_than = "${var.keep_tagged_days * 24 * 60 * 60}s"

    # Only delete images with these tag prefixes
    # Keep release tags forever by excluding them
    tag_prefixes = ["dev-", "staging-", "pr-", "branch-"]
  }
}

# Keep policy - ensure we always retain a minimum number of versions
resource "google_artifact_registry_repository_cleanup_policy" "keep_minimum" {
  project    = var.project_id
  location   = var.location
  repository = google_artifact_registry_repository.repo.name
  policy_id  = "keep-minimum-versions"

  action = "KEEP"

  most_recent_versions {
    keep_count = var.keep_minimum_versions
  }
}

# Keep production release tags indefinitely
resource "google_artifact_registry_repository_cleanup_policy" "keep_releases" {
  project    = var.project_id
  location   = var.location
  repository = google_artifact_registry_repository.repo.name
  policy_id  = "keep-releases"

  action = "KEEP"

  condition {
    tag_state    = "TAGGED"
    tag_prefixes = ["v", "release-", "prod-"]
  }
}
```

A few things to note about cleanup policies. The `KEEP` action takes priority over `DELETE` - if an image matches both a keep and delete policy, it is kept. Always start with `cleanup_policy_dry_run = true` and check the logs before enabling actual deletion. Once you are confident the policies are correct, set it to `false`.

## Vulnerability Scanning

Artifact Registry integrates with Container Analysis for automatic vulnerability scanning:

```hcl
# scanning.tf - Vulnerability scanning configuration

# Enable the Container Analysis API for vulnerability scanning
resource "google_project_service" "container_analysis" {
  project = var.project_id
  service = "containeranalysis.googleapis.com"

  disable_dependent_services = false
  disable_on_destroy         = false
}

# Enable the Container Scanning API
resource "google_project_service" "container_scanning" {
  project = var.project_id
  service = "containerscanning.googleapis.com"

  disable_dependent_services = false
  disable_on_destroy         = false
}

# Create an alert policy for critical vulnerabilities
resource "google_monitoring_alert_policy" "critical_vulnerabilities" {
  count = var.vulnerability_scanning_enabled ? 1 : 0

  project      = var.project_id
  display_name = "Critical Container Vulnerabilities - ${var.repository_id}"

  conditions {
    display_name = "Critical or high severity vulnerabilities found"

    condition_threshold {
      filter = <<-FILTER
        resource.type = "global" AND
        metric.type = "logging.googleapis.com/user/critical-container-vulnerabilities"
      FILTER

      comparison      = "COMPARISON_GT"
      threshold_value = 0
      duration        = "0s"

      aggregations {
        alignment_period   = "60s"
        per_series_aligner = "ALIGN_COUNT"
      }
    }
  }

  notification_channels = var.notification_channels

  documentation {
    content = "Critical or high severity vulnerabilities were detected in images pushed to ${var.repository_id}. Review the Container Analysis findings in the GCP Console."
  }
}

# Log-based metric for tracking vulnerability occurrences
resource "google_logging_metric" "critical_vulnerabilities" {
  count = var.vulnerability_scanning_enabled ? 1 : 0

  project = var.project_id
  name    = "critical-container-vulnerabilities"

  filter = <<-FILTER
    resource.type="global"
    protoPayload.serviceName="containeranalysis.googleapis.com"
    protoPayload.methodName="grafeas.v1.Grafeas.CreateOccurrence"
    protoPayload.request.occurrence.vulnerability.effectiveSeverity=("CRITICAL" OR "HIGH")
  FILTER

  metric_descriptor {
    metric_kind = "DELTA"
    value_type  = "INT64"
  }
}
```

## IAM Access Controls

Set up who can push and pull images:

```hcl
# iam.tf - Repository access controls

# Read access for image consumers (CI/CD, GKE, Cloud Run)
resource "google_artifact_registry_repository_iam_member" "readers" {
  for_each = toset(var.readers)

  project    = var.project_id
  location   = var.location
  repository = google_artifact_registry_repository.repo.name
  role       = "roles/artifactregistry.reader"
  member     = each.value
}

# Write access for image publishers (CI/CD build service accounts)
resource "google_artifact_registry_repository_iam_member" "writers" {
  for_each = toset(var.writers)

  project    = var.project_id
  location   = var.location
  repository = google_artifact_registry_repository.repo.name
  role       = "roles/artifactregistry.writer"
  member     = each.value
}

# Grant the GKE service account read access
resource "google_artifact_registry_repository_iam_member" "gke_reader" {
  count = var.gke_service_account_email != "" ? 1 : 0

  project    = var.project_id
  location   = var.location
  repository = google_artifact_registry_repository.repo.name
  role       = "roles/artifactregistry.reader"
  member     = "serviceAccount:${var.gke_service_account_email}"
}
```

## Outputs

```hcl
# outputs.tf - Values for consumers of this module

output "repository_id" {
  description = "The repository ID"
  value       = google_artifact_registry_repository.repo.repository_id
}

output "repository_name" {
  description = "Full resource name of the repository"
  value       = google_artifact_registry_repository.repo.name
}

output "docker_registry_url" {
  description = "Docker registry URL for pushing/pulling images"
  value       = "${var.location}-docker.pkg.dev/${var.project_id}/${var.repository_id}"
}
```

## Using the Module

Here is how to use the module in your environment:

```hcl
# Deploy an Artifact Registry repository for the backend team
module "backend_registry" {
  source = "./modules/artifact-registry"

  project_id    = "my-project"
  location      = "us-central1"
  repository_id = "backend"
  description   = "Backend service container images"

  # Tag immutability for release tags
  immutable_tags = true

  # Cleanup configuration
  keep_tagged_days      = 90
  keep_untagged_days    = 7
  keep_minimum_versions = 10
  cleanup_policy_dry_run = false

  # Access control
  readers = [
    "serviceAccount:gke-nodes@my-project.iam.gserviceaccount.com",
    "serviceAccount:cloud-run@my-project.iam.gserviceaccount.com",
  ]

  writers = [
    "serviceAccount:ci-builder@my-project.iam.gserviceaccount.com",
  ]

  labels = {
    team        = "backend"
    environment = "production"
  }
}

# Output the registry URL for CI/CD configuration
output "backend_registry_url" {
  value = module.backend_registry.docker_registry_url
}
```

## Querying Scan Results

After pushing an image, check scan results:

```bash
# List vulnerabilities for a specific image
gcloud artifacts docker images list-vulnerabilities \
  us-central1-docker.pkg.dev/my-project/backend/my-app@sha256:abc123 \
  --project=my-project

# List all images with critical vulnerabilities
gcloud artifacts docker images list \
  us-central1-docker.pkg.dev/my-project/backend \
  --include-tags \
  --show-occurrences \
  --occurrence-filter='kind="VULNERABILITY" AND vulnerability.effectiveSeverity="CRITICAL"' \
  --project=my-project
```

## Summary

This Terraform module creates a well-managed Artifact Registry setup with three key features: automatic vulnerability scanning to catch security issues at push time, cleanup policies to prevent unbounded storage growth, and fine-grained IAM controls to manage who can push and pull images. The cleanup policies alone will save significant storage costs over time, and the vulnerability scanning gives your security team visibility into the container supply chain.
