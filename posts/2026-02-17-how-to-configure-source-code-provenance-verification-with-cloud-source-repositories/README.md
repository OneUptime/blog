# How to Configure Source Code Provenance Verification with Cloud Source Repositories

Author: [nawazdhandala](https://www.github.com/nawazdhandala)

Tags: GCP, Cloud Source Repositories, Supply Chain Security, Provenance, SLSA

Description: Set up source code provenance verification on GCP to track and verify the origin and integrity of code flowing through your build pipeline using SLSA principles.

---

Software supply chain attacks are increasingly common, and knowing where your code comes from - and that it hasn't been tampered with - is no longer optional. Source code provenance verification answers the question: can I prove that this binary was built from this specific commit in this specific repository, and that nothing was modified along the way?

GCP provides the building blocks for provenance verification through Cloud Source Repositories, Cloud Build, and the SLSA (Supply-chain Levels for Software Artifacts) framework. In this post, I'll walk through setting up a provenance pipeline that tracks code from commit to deployment.

## What Is Source Code Provenance?

Provenance is metadata about how a software artifact was produced. For source code, this includes which repository the code came from, which commit was built, who authored and reviewed the changes, and what build process was used to produce the final artifact.

SLSA defines four levels of supply chain security, ranging from Level 1 (basic provenance documentation) to Level 4 (hermetic, reproducible builds with two-party review). We'll target Level 3, which requires a signed, non-falsifiable provenance record generated by the build service.

## Setting Up Cloud Source Repositories

Start by configuring your repository with branch protection and audit logging:

```bash
# Create a Cloud Source Repository
gcloud source repos create my-application

# Clone and configure it
gcloud source repos clone my-application
cd my-application

# Set up commit signing (developers should do this locally)
git config commit.gpgsign true
git config user.signingkey YOUR_GPG_KEY_ID
```

Enable audit logging for the repository so every access event is recorded:

```bash
# Enable Data Access audit logs for Cloud Source Repositories
gcloud projects set-iam-policy YOUR_PROJECT <(
  gcloud projects get-iam-policy YOUR_PROJECT --format=json | \
  python3 -c "
import json, sys
policy = json.load(sys.stdin)
audit_config = {
    'service': 'sourcerepo.googleapis.com',
    'auditLogConfigs': [
        {'logType': 'ADMIN_READ'},
        {'logType': 'DATA_READ'},
        {'logType': 'DATA_WRITE'}
    ]
}
configs = policy.setdefault('auditConfigs', [])
configs.append(audit_config)
json.dump(policy, sys.stdout)
"
)
```

## Build Provenance with Cloud Build

Cloud Build can automatically generate SLSA provenance for builds. Enable it in your build config:

```yaml
# cloudbuild.yaml with provenance generation
options:
  # Request provenance generation at SLSA Level 3
  requestedVerifyOption: VERIFIED

steps:
  # Step 1: Verify the source commit is signed
  - name: 'gcr.io/cloud-builders/git'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        # Verify the commit signature
        git verify-commit HEAD 2>&1 || {
          echo "WARNING: Commit is not signed"
          # Depending on policy, you might fail here
        }

        # Record the commit metadata for provenance
        echo "commit=$(git rev-parse HEAD)" > /workspace/provenance-inputs.env
        echo "author=$(git log -1 --format='%ae')" >> /workspace/provenance-inputs.env
        echo "timestamp=$(git log -1 --format='%ci')" >> /workspace/provenance-inputs.env
        echo "repository=$(git remote get-url origin)" >> /workspace/provenance-inputs.env
    id: 'verify-source'

  # Step 2: Build the application
  - name: 'gcr.io/cloud-builders/docker'
    args:
      - 'build'
      - '--build-arg'
      - 'COMMIT_SHA=$COMMIT_SHA'
      - '-t'
      - '${_IMAGE}:$COMMIT_SHA'
      - '.'
    id: 'build'

  # Step 3: Push to Artifact Registry
  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', '${_IMAGE}:$COMMIT_SHA']
    id: 'push'

  # Step 4: Generate and attach provenance metadata
  - name: 'gcr.io/cloud-builders/gcloud'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        # Get the image digest
        DIGEST=$(gcloud artifacts docker images describe \
          "${_IMAGE}:$COMMIT_SHA" \
          --format='value(image_summary.digest)')

        # Create a provenance attestation
        cat > /workspace/provenance.json << PROVENANCE
        {
          "_type": "https://in-toto.io/Statement/v0.1",
          "predicateType": "https://slsa.dev/provenance/v0.2",
          "subject": [
            {
              "name": "${_IMAGE}",
              "digest": {
                "sha256": "${DIGEST#sha256:}"
              }
            }
          ],
          "predicate": {
            "builder": {
              "id": "https://cloudbuild.googleapis.com/$PROJECT_ID"
            },
            "buildType": "https://cloud.google.com/build/v1",
            "invocation": {
              "configSource": {
                "uri": "https://source.cloud.google.com/$PROJECT_ID/my-application",
                "digest": {
                  "sha1": "$COMMIT_SHA"
                },
                "entryPoint": "cloudbuild.yaml"
              }
            },
            "metadata": {
              "buildInvocationId": "$BUILD_ID",
              "buildStartedOn": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
              "completeness": {
                "parameters": true,
                "environment": true,
                "materials": true
              }
            },
            "materials": [
              {
                "uri": "https://source.cloud.google.com/$PROJECT_ID/my-application",
                "digest": {
                  "sha1": "$COMMIT_SHA"
                }
              }
            ]
          }
        }
        PROVENANCE

        echo "Provenance generated for ${_IMAGE}@${DIGEST}"
    id: 'generate-provenance'

images:
  - '${_IMAGE}:$COMMIT_SHA'

substitutions:
  _IMAGE: 'us-central1-docker.pkg.dev/YOUR_PROJECT/app-images/my-application'
```

## Verifying Provenance at Deployment Time

Before deploying, verify the provenance chain from source to artifact:

```python
import json
from google.cloud import artifactregistry_v1
from google.cloud import devtools_cloudbuild_v1

def verify_provenance(image_url, expected_repo, expected_branch):
    """Verify the provenance of a container image before deployment"""

    # Step 1: Get the build that produced this image
    build_client = devtools_cloudbuild_v1.CloudBuildClient()
    image_digest = _get_image_digest(image_url)

    # Search for the build that produced this digest
    builds = build_client.list_builds(
        project_id="your-project-id",
        filter=f'images="{image_url}"',
    )

    target_build = None
    for build in builds.builds:
        if image_digest in str(build.results):
            target_build = build
            break

    if not target_build:
        raise ValueError(f"No build found for image {image_url}")

    # Step 2: Verify the build source matches expected repository
    source = target_build.source
    if expected_repo not in source.repo_source.repo_name:
        raise ValueError(
            f"Build source repo {source.repo_source.repo_name} "
            f"does not match expected {expected_repo}"
        )

    # Step 3: Verify the branch
    if source.repo_source.branch_name != expected_branch:
        raise ValueError(
            f"Build from branch {source.repo_source.branch_name}, "
            f"expected {expected_branch}"
        )

    # Step 4: Verify the build was triggered by Cloud Build (not manual)
    if target_build.build_trigger_id == "":
        raise ValueError("Build was not triggered by a Cloud Build trigger")

    # Step 5: Check that provenance was generated
    provenance = target_build.results.artifact_manifest
    if not provenance:
        raise ValueError("Build does not have provenance metadata")

    return {
        "verified": True,
        "build_id": target_build.id,
        "source_repo": source.repo_source.repo_name,
        "commit_sha": source.repo_source.commit_sha,
        "branch": source.repo_source.branch_name,
        "trigger_id": target_build.build_trigger_id,
    }
```

## Enforcing Provenance Policies with Admission Controller

Create a GKE admission webhook that checks provenance before allowing deployments:

```python
from flask import Flask, request, jsonify
import base64
import json

app = Flask(__name__)

# Policy configuration
PROVENANCE_POLICY = {
    "required_builder": "https://cloudbuild.googleapis.com",
    "allowed_repos": [
        "my-application",
        "shared-libraries",
    ],
    "require_signed_commits": True,
    "allowed_branches": ["main", "release/*"],
}

@app.route("/validate", methods=["POST"])
def validate_admission():
    """Kubernetes admission webhook for provenance verification"""
    admission_review = request.get_json()
    pod_spec = admission_review["request"]["object"]["spec"]

    # Check each container image in the pod
    for container in pod_spec.get("containers", []):
        image = container["image"]

        try:
            provenance = get_provenance(image)
            validate_against_policy(provenance, PROVENANCE_POLICY)
        except Exception as e:
            return jsonify({
                "apiVersion": "admission.k8s.io/v1",
                "kind": "AdmissionReview",
                "response": {
                    "uid": admission_review["request"]["uid"],
                    "allowed": False,
                    "status": {
                        "message": f"Provenance check failed: {str(e)}"
                    },
                },
            })

    # All images passed provenance checks
    return jsonify({
        "apiVersion": "admission.k8s.io/v1",
        "kind": "AdmissionReview",
        "response": {
            "uid": admission_review["request"]["uid"],
            "allowed": True,
        },
    })
```

## Monitoring Provenance Compliance

Track provenance compliance across your organization:

```sql
-- Query Cloud Build logs in BigQuery to track provenance coverage
SELECT
  DATE(create_time) AS build_date,
  COUNTIF(source.repo_source IS NOT NULL) AS builds_with_source,
  COUNTIF(source.repo_source IS NULL) AS builds_without_source,
  COUNTIF(results.artifact_manifest IS NOT NULL) AS builds_with_provenance,
  COUNT(*) AS total_builds,
  ROUND(
    COUNTIF(results.artifact_manifest IS NOT NULL) / COUNT(*) * 100, 1
  ) AS provenance_coverage_pct
FROM `your-project.cloud_build.builds`
WHERE create_time > TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 30 DAY)
GROUP BY build_date
ORDER BY build_date DESC
```

## Wrapping Up

Source code provenance verification creates an auditable trail from code commit to deployed artifact. By combining Cloud Source Repositories for version control, Cloud Build for provenance generation, and admission webhooks for enforcement, you get a system that can prove - not just claim - that your deployments come from trusted, reviewed code. This isn't just a security best practice; for many organizations, it's becoming a compliance requirement. Start by enabling provenance generation in your builds, then gradually add verification gates as your team gets comfortable with the workflow.
