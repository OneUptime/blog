# How to Set Up Wazuh Security Platform on Ubuntu

Author: [nawazdhandala](https://www.github.com/nawazdhandala)

Tags: Ubuntu, Wazuh, SIEM, Security, XDR, Tutorial

Description: Complete guide to installing Wazuh unified security platform on Ubuntu for threat detection and compliance.

---

Wazuh is a free, open-source security platform that provides unified XDR (Extended Detection and Response) and SIEM (Security Information and Event Management) capabilities. It offers comprehensive protection for workloads across on-premises, virtualized, containerized, and cloud environments. This guide walks you through the complete installation and configuration of Wazuh on Ubuntu, including advanced features like file integrity monitoring, vulnerability detection, and compliance monitoring.

## Understanding Wazuh Components

Before diving into the installation, it's essential to understand the architecture of Wazuh. The platform consists of four main components:

### Wazuh Indexer

The Wazuh indexer is a highly scalable, full-text search and analytics engine based on OpenSearch. It stores alerts generated by the Wazuh server and provides the backend for the Wazuh dashboard. Key features include:

- Real-time indexing of security events
- Powerful query language for threat hunting
- Data retention and lifecycle management
- Cluster support for high availability

### Wazuh Server

The Wazuh server is the central component that analyzes data received from agents. It processes events through decoders and rules to generate security alerts. The server includes:

- **Analysis engine**: Processes incoming events and generates alerts
- **Registration service**: Manages agent enrollment
- **RESTful API**: Enables programmatic access to configuration and data
- **Cluster daemon**: Supports horizontal scaling across multiple servers

### Wazuh Dashboard

The Wazuh dashboard is a web-based user interface built on OpenSearch Dashboards. It provides:

- Real-time visualization of security events
- Pre-built dashboards for compliance monitoring
- Agent management interface
- Rule testing and development tools

### Wazuh Agents

Agents are lightweight programs installed on monitored endpoints. They collect system data and forward it to the Wazuh server for analysis. Agents support:

- Log collection and forwarding
- File integrity monitoring
- System inventory
- Active response execution
- Rootkit detection

## Prerequisites

Before installing Wazuh, ensure your system meets the following requirements:

### Hardware Requirements

For a production environment with up to 100 agents:

| Component | CPU | RAM | Storage |
|-----------|-----|-----|---------|
| Wazuh Indexer | 4 cores | 8 GB | 50 GB SSD |
| Wazuh Server | 4 cores | 8 GB | 50 GB SSD |
| Wazuh Dashboard | 2 cores | 4 GB | 20 GB SSD |

For larger deployments, consider distributed installations with multiple nodes.

### Software Requirements

- Ubuntu 22.04 LTS or Ubuntu 24.04 LTS
- Root or sudo privileges
- Open network ports (1514, 1515, 1516, 55000, 9200, 443)

### Network Configuration

Ensure the following ports are accessible:

```bash
# Wazuh server ports
# 1514/TCP - Agent communication (events)
# 1515/TCP - Agent enrollment
# 1516/TCP - Cluster daemon
# 55000/TCP - Wazuh API

# Wazuh indexer ports
# 9200/TCP - Indexer RESTful API

# Wazuh dashboard ports
# 443/TCP - Web interface (HTTPS)
```

Let's prepare the system:

```bash
# Update the system packages
sudo apt update && sudo apt upgrade -y

# Install required dependencies
sudo apt install -y curl apt-transport-https unzip wget libcap2-bin

# Configure system limits for Wazuh indexer
# These settings optimize memory mapping for the indexer
cat << 'EOF' | sudo tee /etc/sysctl.d/99-wazuh.conf
# Increase virtual memory areas for Wazuh indexer
vm.max_map_count=262144

# Optimize network settings for high connection counts
net.core.somaxconn=65535
net.ipv4.tcp_max_syn_backlog=65535
EOF

# Apply sysctl settings without reboot
sudo sysctl --system

# Verify the settings were applied
sysctl vm.max_map_count
```

## Installing Wazuh Indexer

The Wazuh indexer must be installed first as it provides the data storage backend.

### Step 1: Add Wazuh Repository

```bash
# Import the Wazuh GPG key
curl -s https://packages.wazuh.com/key/GPG-KEY-WAZUH | gpg --no-default-keyring \
  --keyring gnupg-ring:/usr/share/keyrings/wazuh.gpg --import && chmod 644 /usr/share/keyrings/wazuh.gpg

# Add the Wazuh repository
echo "deb [signed-by=/usr/share/keyrings/wazuh.gpg] https://packages.wazuh.com/4.x/apt/ stable main" | \
  sudo tee /etc/apt/sources.list.d/wazuh.list

# Update package information
sudo apt update
```

### Step 2: Generate SSL Certificates

Wazuh uses SSL certificates for secure communication between components. Download and configure the certificate generation tool:

```bash
# Download the Wazuh certificate tool
curl -sO https://packages.wazuh.com/4.9/wazuh-certs-tool.sh

# Download the configuration template
curl -sO https://packages.wazuh.com/4.9/config.yml
```

Edit the configuration file to match your environment:

```yaml
# /root/config.yml
# Certificate configuration for Wazuh components
# Replace IP addresses with your actual server IPs

nodes:
  # Wazuh indexer nodes
  # For single-node installation, use one entry
  # For clusters, add multiple entries with unique names
  indexer:
    - name: wazuh-indexer-1
      ip: "192.168.1.100"      # Replace with your indexer IP
    # - name: wazuh-indexer-2  # Uncomment for cluster setup
    #   ip: "192.168.1.101"
    # - name: wazuh-indexer-3
    #   ip: "192.168.1.102"

  # Wazuh server nodes
  server:
    - name: wazuh-server-1
      ip: "192.168.1.100"      # Replace with your server IP
    # - name: wazuh-server-2  # Uncomment for cluster setup
    #   ip: "192.168.1.101"

  # Wazuh dashboard nodes
  dashboard:
    - name: wazuh-dashboard
      ip: "192.168.1.100"      # Replace with your dashboard IP
```

Generate the certificates:

```bash
# Generate certificates for all nodes
# The -A flag generates certificates for all components defined in config.yml
sudo bash wazuh-certs-tool.sh -A

# Compress certificates for distribution
# This creates a tarball that can be copied to other nodes in distributed setups
cd /root/wazuh-certificates
sudo tar -cvf wazuh-certificates.tar *
sudo mv wazuh-certificates.tar /root/
```

### Step 3: Install and Configure Wazuh Indexer

```bash
# Install Wazuh indexer package
sudo apt install -y wazuh-indexer

# Deploy certificates for the indexer
# Create the certificates directory
sudo mkdir -p /etc/wazuh-indexer/certs

# Extract and install certificates
# NODE_NAME must match the name in config.yml
NODE_NAME="wazuh-indexer-1"
cd /root
sudo tar -xf wazuh-certificates.tar -C /etc/wazuh-indexer/certs/ \
  ./${NODE_NAME}.pem \
  ./${NODE_NAME}-key.pem \
  ./admin.pem \
  ./admin-key.pem \
  ./root-ca.pem

# Rename certificates to expected names
sudo mv /etc/wazuh-indexer/certs/${NODE_NAME}.pem /etc/wazuh-indexer/certs/indexer.pem
sudo mv /etc/wazuh-indexer/certs/${NODE_NAME}-key.pem /etc/wazuh-indexer/certs/indexer-key.pem

# Set proper permissions
# Certificates must be readable only by the wazuh-indexer user
sudo chmod 500 /etc/wazuh-indexer/certs
sudo chmod 400 /etc/wazuh-indexer/certs/*
sudo chown -R wazuh-indexer:wazuh-indexer /etc/wazuh-indexer/certs
```

Configure the indexer:

```yaml
# /etc/wazuh-indexer/opensearch.yml
# Main configuration file for Wazuh indexer

# ======================== Network Configuration ========================
# Bind to specific IP address or 0.0.0.0 for all interfaces
network.host: "192.168.1.100"

# Node name must match certificate common name
node.name: "wazuh-indexer-1"

# Cluster configuration
# For single-node setup, use the same name for initial_master_nodes
cluster.initial_master_nodes:
  - "wazuh-indexer-1"

cluster.name: "wazuh-cluster"

# Discovery configuration for cluster
# List all indexer nodes for cluster discovery
discovery.seed_hosts:
  - "192.168.1.100"

# ======================== Path Configuration ========================
path.data: /var/lib/wazuh-indexer
path.logs: /var/log/wazuh-indexer

# ======================== Security Configuration ========================
# Enable security plugin
plugins.security.ssl.http.enabled: true
plugins.security.ssl.http.pemcert_filepath: /etc/wazuh-indexer/certs/indexer.pem
plugins.security.ssl.http.pemkey_filepath: /etc/wazuh-indexer/certs/indexer-key.pem
plugins.security.ssl.http.pemtrustedcas_filepath: /etc/wazuh-indexer/certs/root-ca.pem

plugins.security.ssl.transport.enabled: true
plugins.security.ssl.transport.pemcert_filepath: /etc/wazuh-indexer/certs/indexer.pem
plugins.security.ssl.transport.pemkey_filepath: /etc/wazuh-indexer/certs/indexer-key.pem
plugins.security.ssl.transport.pemtrustedcas_filepath: /etc/wazuh-indexer/certs/root-ca.pem
plugins.security.ssl.transport.enforce_hostname_verification: false

# Admin certificate for security operations
plugins.security.authcz.admin_dn:
  - "CN=admin,OU=Wazuh,O=Wazuh,L=California,C=US"

# Node distinguished names
plugins.security.nodes_dn:
  - "CN=wazuh-indexer-1,OU=Wazuh,O=Wazuh,L=California,C=US"

# ======================== Performance Configuration ========================
# Disable performance analyzer for better resource usage
plugins.security.audit.type: internal_opensearch
plugins.security.enable_snapshot_restore_privilege: true
plugins.security.check_snapshot_restore_write_privileges: true
plugins.security.restapi.roles_enabled: ["all_access", "security_rest_api_access"]

# Index settings
# Adjust based on available memory
indices.query.bool.max_clause_count: 4096
```

### Step 4: Start and Initialize the Indexer

```bash
# Enable and start the Wazuh indexer service
sudo systemctl daemon-reload
sudo systemctl enable wazuh-indexer
sudo systemctl start wazuh-indexer

# Wait for the service to fully start
sleep 30

# Initialize the security settings
# This script configures internal users and security settings
sudo /usr/share/wazuh-indexer/bin/indexer-security-init.sh

# Verify the indexer is running
# Expected output: green or yellow cluster health status
curl -k -u admin:admin https://localhost:9200/_cluster/health?pretty
```

Expected output:

```json
{
  "cluster_name" : "wazuh-cluster",
  "status" : "green",
  "timed_out" : false,
  "number_of_nodes" : 1,
  "number_of_data_nodes" : 1,
  "active_primary_shards" : 7,
  "active_shards" : 7,
  "relocating_shards" : 0,
  "initializing_shards" : 0,
  "unassigned_shards" : 0,
  "delayed_unassigned_shards" : 0,
  "number_of_pending_tasks" : 0,
  "number_of_in_flight_fetch" : 0,
  "task_max_waiting_in_queue_millis" : 0,
  "active_shards_percent_as_number" : 100.0
}
```

## Installing Wazuh Server

The Wazuh server processes events from agents and generates security alerts.

### Step 1: Install Wazuh Manager

```bash
# Install Wazuh manager package
sudo apt install -y wazuh-manager

# Deploy certificates for the server
sudo mkdir -p /etc/wazuh-manager/certs
cd /root
sudo tar -xf wazuh-certificates.tar -C /etc/wazuh-manager/certs/ \
  ./wazuh-server-1.pem \
  ./wazuh-server-1-key.pem \
  ./root-ca.pem

# Rename to expected names
sudo mv /etc/wazuh-manager/certs/wazuh-server-1.pem /etc/wazuh-manager/certs/server.pem
sudo mv /etc/wazuh-manager/certs/wazuh-server-1-key.pem /etc/wazuh-manager/certs/server-key.pem

# Set permissions
sudo chmod 500 /etc/wazuh-manager/certs
sudo chmod 400 /etc/wazuh-manager/certs/*
sudo chown -R root:wazuh /etc/wazuh-manager/certs
```

### Step 2: Configure Wazuh Manager

The main configuration file is `/var/ossec/etc/ossec.conf`. Here's a comprehensive configuration:

```xml
<!-- /var/ossec/etc/ossec.conf -->
<!-- Main Wazuh manager configuration file -->

<ossec_config>

  <!-- ======================== Global Settings ======================== -->
  <global>
    <!-- Email notification settings -->
    <!-- Enable for email alerts on critical events -->
    <email_notification>no</email_notification>
    <smtp_server>smtp.example.com</smtp_server>
    <email_from>wazuh@example.com</email_from>
    <email_to>security@example.com</email_to>
    <email_maxperhour>12</email_maxperhour>

    <!-- Log format: plain or json -->
    <logall>no</logall>
    <logall_json>yes</logall_json>

    <!-- GeoIP database for location enrichment -->
    <geoip_db_path>/var/ossec/etc/GeoLite2-City.mmdb</geoip_db_path>
  </global>

  <!-- ======================== Alert Settings ======================== -->
  <alerts>
    <!-- Minimum severity level to log alerts (0-16) -->
    <log_alert_level>3</log_alert_level>
    <!-- Minimum severity level for email alerts -->
    <email_alert_level>12</email_alert_level>
  </alerts>

  <!-- ======================== Remote Connection Settings ======================== -->
  <remote>
    <!-- Accept connections from agents -->
    <connection>secure</connection>
    <port>1514</port>
    <protocol>tcp</protocol>
    <!-- Queue size for incoming events -->
    <queue_size>131072</queue_size>
  </remote>

  <!-- ======================== Indexer Integration ======================== -->
  <!-- Configure connection to Wazuh indexer -->
  <indexer>
    <enabled>yes</enabled>
    <hosts>
      <host>https://192.168.1.100:9200</host>
    </hosts>
    <ssl>
      <certificate_authorities>
        <ca>/etc/wazuh-manager/certs/root-ca.pem</ca>
      </certificate_authorities>
      <certificate>/etc/wazuh-manager/certs/server.pem</certificate>
      <key>/etc/wazuh-manager/certs/server-key.pem</key>
    </ssl>
  </indexer>

  <!-- ======================== Vulnerability Detector ======================== -->
  <!-- Enable vulnerability scanning for monitored hosts -->
  <vulnerability-detector>
    <enabled>yes</enabled>
    <interval>5m</interval>
    <min_full_scan_interval>6h</min_full_scan_interval>
    <run_on_start>yes</run_on_start>

    <!-- Ubuntu vulnerability feed -->
    <provider name="canonical">
      <enabled>yes</enabled>
      <os>jammy</os>
      <os>noble</os>
      <update_interval>1h</update_interval>
    </provider>

    <!-- Debian vulnerability feed -->
    <provider name="debian">
      <enabled>yes</enabled>
      <os>bullseye</os>
      <os>bookworm</os>
      <update_interval>1h</update_interval>
    </provider>

    <!-- Red Hat vulnerability feed -->
    <provider name="redhat">
      <enabled>yes</enabled>
      <os>8</os>
      <os>9</os>
      <update_interval>1h</update_interval>
    </provider>

    <!-- National Vulnerability Database -->
    <provider name="nvd">
      <enabled>yes</enabled>
      <update_interval>1h</update_interval>
    </provider>
  </vulnerability-detector>

  <!-- ======================== Log Analysis ======================== -->
  <!-- Configure log sources to monitor -->
  <localfile>
    <log_format>syslog</log_format>
    <location>/var/log/syslog</location>
  </localfile>

  <localfile>
    <log_format>syslog</log_format>
    <location>/var/log/auth.log</location>
  </localfile>

  <localfile>
    <log_format>syslog</log_format>
    <location>/var/log/dpkg.log</location>
  </localfile>

  <localfile>
    <log_format>json</log_format>
    <location>/var/log/audit/audit.log</location>
  </localfile>

  <!-- ======================== System Inventory ======================== -->
  <wodle name="syscollector">
    <disabled>no</disabled>
    <interval>1h</interval>
    <scan_on_start>yes</scan_on_start>
    <!-- Collect hardware information -->
    <hardware>yes</hardware>
    <!-- Collect operating system information -->
    <os>yes</os>
    <!-- Collect network interface information -->
    <network>yes</network>
    <!-- Collect installed packages -->
    <packages>yes</packages>
    <!-- Collect running processes -->
    <processes>yes</processes>
    <!-- Collect listening ports -->
    <ports all="no">yes</ports>
    <!-- Collect network hotfixes (Windows) -->
    <hotfixes>yes</hotfixes>
  </wodle>

  <!-- ======================== CIS-CAT Integration ======================== -->
  <!-- Enable CIS benchmark scanning -->
  <wodle name="cis-cat">
    <disabled>yes</disabled>
    <timeout>1800</timeout>
    <interval>1d</interval>
    <scan-on-start>yes</scan-on-start>
    <java_path>/usr/bin/java</java_path>
    <ciscat_path>/var/ossec/wodles/ciscat</ciscat_path>
  </wodle>

  <!-- ======================== Security Configuration Assessment ======================== -->
  <sca>
    <enabled>yes</enabled>
    <scan_on_start>yes</scan_on_start>
    <interval>12h</interval>
    <skip_nfs>yes</skip_nfs>
  </sca>

  <!-- ======================== Rootcheck Settings ======================== -->
  <rootcheck>
    <disabled>no</disabled>
    <check_files>yes</check_files>
    <check_trojans>yes</check_trojans>
    <check_dev>yes</check_dev>
    <check_sys>yes</check_sys>
    <check_pids>yes</check_pids>
    <check_ports>yes</check_ports>
    <check_if>yes</check_if>
    <frequency>43200</frequency>
    <rootkit_files>/var/ossec/etc/shared/rootkit_files.txt</rootkit_files>
    <rootkit_trojans>/var/ossec/etc/shared/rootkit_trojans.txt</rootkit_trojans>
  </rootcheck>

  <!-- ======================== Active Response ======================== -->
  <!-- Define automated responses to security events -->
  <command>
    <name>firewall-drop</name>
    <executable>firewall-drop</executable>
    <timeout_allowed>yes</timeout_allowed>
  </command>

  <command>
    <name>disable-account</name>
    <executable>disable-account</executable>
    <timeout_allowed>yes</timeout_allowed>
  </command>

  <!-- Block IP after multiple failed SSH attempts -->
  <active-response>
    <command>firewall-drop</command>
    <location>local</location>
    <rules_id>5763</rules_id>
    <timeout>600</timeout>
  </active-response>

  <!-- ======================== Cluster Configuration ======================== -->
  <!-- Enable for multi-node Wazuh server deployment -->
  <cluster>
    <name>wazuh-cluster</name>
    <node_name>wazuh-server-1</node_name>
    <node_type>master</node_type>
    <key>CLUSTER_KEY_CHANGE_ME</key>
    <port>1516</port>
    <bind_addr>0.0.0.0</bind_addr>
    <nodes>
      <node>192.168.1.100</node>
    </nodes>
    <hidden>no</hidden>
    <disabled>yes</disabled>
  </cluster>

</ossec_config>
```

### Step 3: Install Filebeat for Alert Forwarding

Filebeat forwards alerts from the Wazuh server to the indexer:

```bash
# Install Filebeat
sudo apt install -y filebeat

# Download Wazuh Filebeat module
curl -s https://packages.wazuh.com/4.x/filebeat/wazuh-filebeat-0.4.tar.gz | \
  sudo tar -xvz -C /usr/share/filebeat/module

# Download Filebeat configuration template
sudo curl -so /etc/filebeat/filebeat.yml \
  https://packages.wazuh.com/4.9/tpl/wazuh/filebeat/filebeat.yml

# Download alerts template
sudo curl -so /etc/filebeat/wazuh-template.json \
  https://packages.wazuh.com/4.9/tpl/wazuh/filebeat/wazuh-template.json

# Set proper permissions
sudo chmod go+r /etc/filebeat/wazuh-template.json
```

Configure Filebeat:

```yaml
# /etc/filebeat/filebeat.yml
# Filebeat configuration for Wazuh alert forwarding

# ======================== Filebeat Inputs ========================
filebeat.modules:
  - module: wazuh
    alerts:
      enabled: true
    archives:
      enabled: false

# ======================== Elasticsearch Output ========================
output.elasticsearch:
  hosts: ["192.168.1.100:9200"]
  protocol: https
  username: admin
  password: admin
  ssl:
    certificate_authorities:
      - /etc/filebeat/certs/root-ca.pem
    certificate: /etc/filebeat/certs/filebeat.pem
    key: /etc/filebeat/certs/filebeat-key.pem
    verification_mode: full

# ======================== Template Settings ========================
setup.template.json.enabled: true
setup.template.json.path: /etc/filebeat/wazuh-template.json
setup.template.json.name: wazuh
setup.template.overwrite: true
setup.ilm.enabled: false

# ======================== Kibana Configuration ========================
# Required for dashboard setup
setup.kibana:
  host: "https://192.168.1.100:443"
  ssl:
    enabled: true
    certificate_authorities:
      - /etc/filebeat/certs/root-ca.pem

# ======================== Logging ========================
logging.level: info
logging.to_files: true
logging.files:
  path: /var/log/filebeat
  name: filebeat
  keepfiles: 7
  permissions: 0640
```

Deploy certificates for Filebeat:

```bash
# Create certificates directory
sudo mkdir -p /etc/filebeat/certs

# Extract certificates
cd /root
sudo tar -xf wazuh-certificates.tar -C /etc/filebeat/certs/ \
  ./wazuh-server-1.pem \
  ./wazuh-server-1-key.pem \
  ./root-ca.pem

# Rename certificates
sudo mv /etc/filebeat/certs/wazuh-server-1.pem /etc/filebeat/certs/filebeat.pem
sudo mv /etc/filebeat/certs/wazuh-server-1-key.pem /etc/filebeat/certs/filebeat-key.pem

# Set permissions
sudo chmod 500 /etc/filebeat/certs
sudo chmod 400 /etc/filebeat/certs/*
sudo chown -R root:root /etc/filebeat/certs
```

Start the services:

```bash
# Enable and start Wazuh manager
sudo systemctl daemon-reload
sudo systemctl enable wazuh-manager
sudo systemctl start wazuh-manager

# Enable and start Filebeat
sudo systemctl enable filebeat
sudo systemctl start filebeat

# Verify Filebeat connectivity
sudo filebeat test output
```

## Installing Wazuh Dashboard

The dashboard provides a web-based interface for managing Wazuh.

### Step 1: Install Dashboard Package

```bash
# Install Wazuh dashboard
sudo apt install -y wazuh-dashboard

# Deploy certificates
sudo mkdir -p /etc/wazuh-dashboard/certs
cd /root
sudo tar -xf wazuh-certificates.tar -C /etc/wazuh-dashboard/certs/ \
  ./wazuh-dashboard.pem \
  ./wazuh-dashboard-key.pem \
  ./root-ca.pem

# Rename certificates
sudo mv /etc/wazuh-dashboard/certs/wazuh-dashboard.pem /etc/wazuh-dashboard/certs/dashboard.pem
sudo mv /etc/wazuh-dashboard/certs/wazuh-dashboard-key.pem /etc/wazuh-dashboard/certs/dashboard-key.pem

# Set permissions
sudo chmod 500 /etc/wazuh-dashboard/certs
sudo chmod 400 /etc/wazuh-dashboard/certs/*
sudo chown -R wazuh-dashboard:wazuh-dashboard /etc/wazuh-dashboard/certs
```

### Step 2: Configure Dashboard

```yaml
# /etc/wazuh-dashboard/opensearch_dashboards.yml
# Wazuh dashboard configuration

# ======================== Server Settings ========================
# Port to listen on
server.port: 443

# Bind address (0.0.0.0 for all interfaces)
server.host: "0.0.0.0"

# Server name displayed in browser
server.name: "wazuh-dashboard"

# ======================== SSL/TLS Configuration ========================
server.ssl.enabled: true
server.ssl.certificate: /etc/wazuh-dashboard/certs/dashboard.pem
server.ssl.key: /etc/wazuh-dashboard/certs/dashboard-key.pem

# ======================== OpenSearch Connection ========================
opensearch.hosts: ["https://192.168.1.100:9200"]
opensearch.username: kibanaserver
opensearch.password: kibanaserver
opensearch.ssl.certificateAuthorities: ["/etc/wazuh-dashboard/certs/root-ca.pem"]
opensearch.ssl.verificationMode: full

# ======================== Security Plugin ========================
opensearch_security.multitenancy.enabled: false
opensearch_security.readonly_mode.roles: ["kibana_read_only"]
opensearch_security.cookie.secure: true

# ======================== Wazuh Plugin Configuration ========================
# These settings configure the Wazuh plugin
uiSettings.overrides.defaultRoute: /app/wazuh
```

### Step 3: Start Dashboard

```bash
# Enable and start the dashboard service
sudo systemctl daemon-reload
sudo systemctl enable wazuh-dashboard
sudo systemctl start wazuh-dashboard

# Check service status
sudo systemctl status wazuh-dashboard

# View logs if needed
sudo journalctl -u wazuh-dashboard -f
```

Access the dashboard at `https://your-server-ip`. Default credentials:
- Username: `admin`
- Password: `admin`

**Important**: Change the default password immediately after first login.

## Agent Deployment

Wazuh agents collect security data from monitored endpoints.

### Installing Agent on Ubuntu/Debian

```bash
# On the monitored host, add Wazuh repository
curl -s https://packages.wazuh.com/key/GPG-KEY-WAZUH | gpg --no-default-keyring \
  --keyring gnupg-ring:/usr/share/keyrings/wazuh.gpg --import && chmod 644 /usr/share/keyrings/wazuh.gpg

echo "deb [signed-by=/usr/share/keyrings/wazuh.gpg] https://packages.wazuh.com/4.x/apt/ stable main" | \
  sudo tee /etc/apt/sources.list.d/wazuh.list

sudo apt update

# Install agent with manager address
# Replace WAZUH_MANAGER with your server IP
WAZUH_MANAGER="192.168.1.100" sudo apt install -y wazuh-agent

# Start the agent
sudo systemctl daemon-reload
sudo systemctl enable wazuh-agent
sudo systemctl start wazuh-agent
```

### Installing Agent on CentOS/RHEL

```bash
# Add Wazuh repository
sudo rpm --import https://packages.wazuh.com/key/GPG-KEY-WAZUH

cat << 'EOF' | sudo tee /etc/yum.repos.d/wazuh.repo
[wazuh]
gpgcheck=1
gpgkey=https://packages.wazuh.com/key/GPG-KEY-WAZUH
enabled=1
name=EL-$releasever - Wazuh
baseurl=https://packages.wazuh.com/4.x/yum/
protect=1
EOF

# Install agent
WAZUH_MANAGER="192.168.1.100" sudo yum install -y wazuh-agent

# Start agent
sudo systemctl daemon-reload
sudo systemctl enable wazuh-agent
sudo systemctl start wazuh-agent
```

### Installing Agent on Windows

```powershell
# Download agent installer (run as Administrator)
Invoke-WebRequest -Uri https://packages.wazuh.com/4.x/windows/wazuh-agent-4.9.0-1.msi `
  -OutFile $env:TEMP\wazuh-agent.msi

# Install with manager address
Start-Process msiexec.exe -Wait -ArgumentList '/i', "$env:TEMP\wazuh-agent.msi", '/q', `
  'WAZUH_MANAGER="192.168.1.100"', 'WAZUH_AGENT_GROUP="default"'

# Start the service
Start-Service -Name WazuhSvc
```

### Agent Configuration

The agent configuration file is `/var/ossec/etc/ossec.conf`:

```xml
<!-- /var/ossec/etc/ossec.conf (Agent) -->
<!-- Wazuh agent configuration -->

<ossec_config>

  <!-- ======================== Server Connection ======================== -->
  <client>
    <server>
      <address>192.168.1.100</address>
      <port>1514</port>
      <protocol>tcp</protocol>
    </server>
    <!-- Enrollment settings -->
    <enrollment>
      <enabled>yes</enabled>
      <manager_address>192.168.1.100</manager_address>
      <port>1515</port>
      <agent_name>ubuntu-web-01</agent_name>
      <groups>linux,webservers</groups>
    </enrollment>
    <!-- Buffer settings for event queuing -->
    <buffer>
      <disabled>no</disabled>
      <queue_size>5000</queue_size>
      <events_per_second>500</events_per_second>
    </buffer>
  </client>

  <!-- ======================== Log Collection ======================== -->
  <localfile>
    <log_format>syslog</log_format>
    <location>/var/log/syslog</location>
  </localfile>

  <localfile>
    <log_format>syslog</log_format>
    <location>/var/log/auth.log</location>
  </localfile>

  <!-- Apache access logs -->
  <localfile>
    <log_format>apache</log_format>
    <location>/var/log/apache2/access.log</location>
  </localfile>

  <!-- Apache error logs -->
  <localfile>
    <log_format>apache</log_format>
    <location>/var/log/apache2/error.log</location>
  </localfile>

  <!-- Nginx access logs -->
  <localfile>
    <log_format>json</log_format>
    <location>/var/log/nginx/access.log</location>
  </localfile>

  <!-- Application logs with custom format -->
  <localfile>
    <log_format>json</log_format>
    <location>/var/log/myapp/*.log</location>
  </localfile>

  <!-- ======================== File Integrity Monitoring ======================== -->
  <!-- Configured in the next section -->

  <!-- ======================== Rootcheck ======================== -->
  <rootcheck>
    <disabled>no</disabled>
    <frequency>43200</frequency>
  </rootcheck>

  <!-- ======================== System Inventory ======================== -->
  <wodle name="syscollector">
    <disabled>no</disabled>
    <interval>1h</interval>
    <scan_on_start>yes</scan_on_start>
    <hardware>yes</hardware>
    <os>yes</os>
    <network>yes</network>
    <packages>yes</packages>
    <ports all="no">yes</ports>
    <processes>yes</processes>
  </wodle>

</ossec_config>
```

## File Integrity Monitoring

File Integrity Monitoring (FIM) detects changes to critical system and application files.

### Basic FIM Configuration

Add the following to your agent's `ossec.conf`:

```xml
<!-- File Integrity Monitoring Configuration -->
<syscheck>
  <!-- Enable FIM -->
  <disabled>no</disabled>

  <!-- Scan frequency in seconds (12 hours) -->
  <frequency>43200</frequency>

  <!-- Enable real-time monitoring for critical directories -->
  <!-- Real-time monitoring uses inotify on Linux -->
  <directories check_all="yes" realtime="yes">/etc</directories>
  <directories check_all="yes" realtime="yes">/usr/bin</directories>
  <directories check_all="yes" realtime="yes">/usr/sbin</directories>
  <directories check_all="yes" realtime="yes">/bin</directories>
  <directories check_all="yes" realtime="yes">/sbin</directories>

  <!-- Monitor boot sector and kernel modules -->
  <directories check_all="yes">/boot</directories>

  <!-- Monitor web application files -->
  <directories check_all="yes" realtime="yes" report_changes="yes">/var/www</directories>

  <!-- Monitor user home directories (without real-time due to volume) -->
  <directories check_all="yes">/home</directories>

  <!-- Monitor cron jobs -->
  <directories check_all="yes" realtime="yes">/etc/cron.d</directories>
  <directories check_all="yes" realtime="yes">/etc/cron.daily</directories>
  <directories check_all="yes" realtime="yes">/etc/cron.hourly</directories>
  <directories check_all="yes" realtime="yes">/etc/cron.weekly</directories>
  <directories check_all="yes" realtime="yes">/etc/cron.monthly</directories>
  <directories check_all="yes" realtime="yes">/var/spool/cron/crontabs</directories>

  <!-- Ignore frequently changing files -->
  <ignore>/etc/mtab</ignore>
  <ignore>/etc/hosts.deny</ignore>
  <ignore>/etc/mail/statistics</ignore>
  <ignore>/etc/random-seed</ignore>
  <ignore>/etc/random.seed</ignore>
  <ignore>/etc/adjtime</ignore>
  <ignore>/etc/prelink.cache</ignore>
  <ignore type="sregex">.log$|.swp$</ignore>

  <!-- Ignore directories -->
  <ignore>/etc/ssl/certs</ignore>

  <!-- Process scheduled scans at low priority -->
  <scan_on_start>yes</scan_on_start>

  <!-- Don't alert on new files (reduce noise) -->
  <alert_new_files>yes</alert_new_files>

  <!-- Windows-specific settings (if applicable) -->
  <windows_registry>HKEY_LOCAL_MACHINE\Software\Classes\batfile</windows_registry>
  <windows_registry>HKEY_LOCAL_MACHINE\Software\Classes\cmdfile</windows_registry>
  <windows_registry arch="both">HKEY_LOCAL_MACHINE\Software\Microsoft\Windows\CurrentVersion\Run</windows_registry>

  <!-- Registry ignore patterns -->
  <registry_ignore>HKEY_LOCAL_MACHINE\Security\Policy\Secrets</registry_ignore>

  <!-- Database synchronization settings -->
  <synchronization>
    <enabled>yes</enabled>
    <interval>5m</interval>
    <max_interval>1h</max_interval>
    <max_eps>10</max_eps>
  </synchronization>

  <!-- Store file hashes in database -->
  <database>disk</database>

  <!-- Skip files larger than this (bytes) -->
  <file_limit>
    <enabled>yes</enabled>
    <entries>100000</entries>
  </file_limit>
</syscheck>
```

### Advanced FIM with Who-Data

Who-data auditing provides information about who modified a file:

```xml
<!-- Enable who-data auditing (requires auditd) -->
<syscheck>
  <directories check_all="yes" whodata="yes">/etc/passwd</directories>
  <directories check_all="yes" whodata="yes">/etc/shadow</directories>
  <directories check_all="yes" whodata="yes">/etc/sudoers</directories>
  <directories check_all="yes" whodata="yes">/etc/ssh/sshd_config</directories>

  <!-- Monitor sensitive configuration files -->
  <directories check_all="yes" whodata="yes" report_changes="yes">/etc/pam.d</directories>
</syscheck>
```

Install and configure auditd for who-data:

```bash
# Install auditd
sudo apt install -y auditd audispd-plugins

# The Wazuh agent will automatically configure audit rules
# Restart the agent after enabling who-data
sudo systemctl restart wazuh-agent
```

## Vulnerability Detection

Wazuh can detect vulnerabilities in installed packages by comparing them against vulnerability databases.

### Enable Vulnerability Detector on Manager

The vulnerability detector runs on the Wazuh server and requires the syscollector data from agents:

```xml
<!-- /var/ossec/etc/ossec.conf on manager -->
<vulnerability-detector>
  <enabled>yes</enabled>
  <interval>5m</interval>
  <min_full_scan_interval>6h</min_full_scan_interval>
  <run_on_start>yes</run_on_start>

  <!-- Operating system vulnerability feeds -->
  <provider name="canonical">
    <enabled>yes</enabled>
    <os>focal</os>
    <os>jammy</os>
    <os>noble</os>
    <update_interval>1h</update_interval>
  </provider>

  <provider name="debian">
    <enabled>yes</enabled>
    <os>buster</os>
    <os>bullseye</os>
    <os>bookworm</os>
    <update_interval>1h</update_interval>
  </provider>

  <provider name="redhat">
    <enabled>yes</enabled>
    <os>7</os>
    <os>8</os>
    <os>9</os>
    <update_interval>1h</update_interval>
  </provider>

  <provider name="amazon">
    <enabled>yes</enabled>
    <update_interval>1h</update_interval>
  </provider>

  <!-- National Vulnerability Database for CVE enrichment -->
  <provider name="nvd">
    <enabled>yes</enabled>
    <update_interval>1h</update_interval>
  </provider>

  <!-- Microsoft vulnerability feed for Windows agents -->
  <provider name="msu">
    <enabled>yes</enabled>
    <update_interval>1h</update_interval>
  </provider>
</vulnerability-detector>
```

### Configure Agents for Vulnerability Scanning

Ensure syscollector is enabled on agents:

```xml
<!-- /var/ossec/etc/ossec.conf on agents -->
<wodle name="syscollector">
  <disabled>no</disabled>
  <interval>1h</interval>
  <scan_on_start>yes</scan_on_start>
  <hardware>yes</hardware>
  <os>yes</os>
  <network>yes</network>
  <!-- Required for vulnerability detection -->
  <packages>yes</packages>
  <ports all="no">yes</ports>
  <processes>yes</processes>
  <!-- For Windows hotfix detection -->
  <hotfixes>yes</hotfixes>
</wodle>
```

### Viewing Vulnerability Data

Access vulnerability data through the dashboard or API:

```bash
# Query vulnerabilities via API
curl -k -X GET "https://localhost:55000/vulnerability?pretty=true" \
  -H "Authorization: Bearer $TOKEN"

# Get vulnerabilities for specific agent
curl -k -X GET "https://localhost:55000/vulnerability/001?pretty=true" \
  -H "Authorization: Bearer $TOKEN"

# Filter critical vulnerabilities
curl -k -X GET "https://localhost:55000/vulnerability?severity=Critical&pretty=true" \
  -H "Authorization: Bearer $TOKEN"
```

## Compliance Monitoring

Wazuh provides built-in compliance monitoring for major regulatory frameworks.

### PCI-DSS Compliance

PCI-DSS (Payment Card Industry Data Security Standard) requirements mapped to Wazuh capabilities:

```xml
<!-- Enable PCI-DSS compliance checking on manager -->
<!-- /var/ossec/etc/ossec.conf -->
<ruleset>
  <!-- Load PCI-DSS rules -->
  <rule_dir>etc/rules</rule_dir>
  <rule_exclude>0215-pci_rules.xml</rule_exclude>
</ruleset>
```

The dashboard provides pre-built PCI-DSS dashboards. Key requirements covered:

| Requirement | Wazuh Capability |
|-------------|------------------|
| 1.x - Firewall Configuration | Log analysis of firewall events |
| 2.x - Default Passwords | Configuration assessment |
| 5.x - Malware Protection | Rootcheck and malware detection |
| 6.x - Secure Systems | Vulnerability detection |
| 8.x - Access Control | Authentication log monitoring |
| 10.x - Logging | Comprehensive log collection |
| 11.x - Security Testing | File integrity monitoring |

### GDPR Compliance

GDPR (General Data Protection Regulation) compliance features:

```xml
<!-- Enable GDPR compliance rules -->
<!-- These rules are enabled by default -->
<ruleset>
  <rule_dir>etc/rules</rule_dir>
  <!-- GDPR rules included by default -->
</ruleset>
```

Key GDPR requirements supported:

- **Article 5 - Data Processing Principles**: Audit logging of all data access
- **Article 25 - Data Protection by Design**: Configuration assessment
- **Article 30 - Records of Processing**: Comprehensive event logging
- **Article 32 - Security of Processing**: FIM, vulnerability detection
- **Article 33 - Breach Notification**: Real-time alerting

### HIPAA Compliance

For healthcare organizations subject to HIPAA:

```xml
<!-- HIPAA compliance configuration -->
<ruleset>
  <rule_dir>etc/rules</rule_dir>
  <!-- Enable HIPAA-specific rules -->
</ruleset>
```

### Security Configuration Assessment (SCA)

SCA provides automated compliance checking against CIS benchmarks:

```xml
<!-- Enable SCA on agents -->
<sca>
  <enabled>yes</enabled>
  <scan_on_start>yes</scan_on_start>
  <interval>12h</interval>
  <skip_nfs>yes</skip_nfs>

  <!-- Specify policies to run -->
  <policies>
    <policy>cis_ubuntu22-04.yml</policy>
    <policy>cis_apache_24.yml</policy>
    <policy>cis_mysql5-6_community.yml</policy>
  </policies>
</sca>
```

Available SCA policies:

```bash
# List available SCA policies
ls /var/ossec/ruleset/sca/

# Common policies:
# - cis_ubuntu22-04.yml
# - cis_debian10.yml
# - cis_rhel8.yml
# - cis_apache_24.yml
# - cis_mysql5-6_community.yml
# - cis_nginx.yml
# - cis_docker.yml
```

## Integration with Third-Party Tools

Wazuh integrates with various security and monitoring tools.

### Slack Integration

Configure Slack notifications for security alerts:

```xml
<!-- /var/ossec/etc/ossec.conf on manager -->
<integration>
  <name>slack</name>
  <hook_url>https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK</hook_url>
  <level>10</level>
  <alert_format>json</alert_format>
  <!-- Only send specific rule alerts -->
  <rule_id>5501,5502,5503,5504</rule_id>
  <!-- Or filter by groups -->
  <group>authentication_failed,sshd</group>
</integration>
```

Create the integration script:

```python
#!/usr/bin/env python3
# /var/ossec/integrations/custom-slack.py
# Custom Slack integration with formatting

import json
import sys
import requests
from datetime import datetime

# Read alert from stdin
alert_file = open(sys.argv[1])
alert_json = json.loads(alert_file.read())
alert_file.close()

# Read webhook URL
hook_url = sys.argv[3]

# Format the message
alert_level = alert_json.get('rule', {}).get('level', 0)
rule_description = alert_json.get('rule', {}).get('description', 'N/A')
agent_name = alert_json.get('agent', {}).get('name', 'N/A')
timestamp = alert_json.get('timestamp', datetime.now().isoformat())

# Set color based on alert level
if alert_level >= 12:
    color = '#FF0000'  # Red for critical
elif alert_level >= 7:
    color = '#FFA500'  # Orange for warning
else:
    color = '#00FF00'  # Green for info

# Build Slack message
slack_message = {
    'attachments': [
        {
            'color': color,
            'title': f'Wazuh Alert - Level {alert_level}',
            'text': rule_description,
            'fields': [
                {'title': 'Agent', 'value': agent_name, 'short': True},
                {'title': 'Time', 'value': timestamp, 'short': True},
                {'title': 'Rule ID', 'value': str(alert_json.get('rule', {}).get('id', 'N/A')), 'short': True}
            ]
        }
    ]
}

# Send to Slack
response = requests.post(hook_url, json=slack_message)
sys.exit(0 if response.status_code == 200 else 1)
```

### PagerDuty Integration

Configure PagerDuty for incident management:

```xml
<!-- /var/ossec/etc/ossec.conf -->
<integration>
  <name>pagerduty</name>
  <api_key>YOUR_PAGERDUTY_INTEGRATION_KEY</api_key>
  <level>12</level>
  <alert_format>json</alert_format>
</integration>
```

### VirusTotal Integration

Scan file hashes against VirusTotal:

```xml
<!-- /var/ossec/etc/ossec.conf -->
<integration>
  <name>virustotal</name>
  <api_key>YOUR_VIRUSTOTAL_API_KEY</api_key>
  <!-- Trigger on FIM alerts -->
  <group>syscheck</group>
  <alert_format>json</alert_format>
</integration>
```

### TheHive Integration

Send alerts to TheHive for case management:

```python
#!/usr/bin/env python3
# /var/ossec/integrations/custom-thehive.py
# TheHive integration for case creation

import json
import sys
import requests
from datetime import datetime

# Configuration
THEHIVE_URL = 'https://thehive.example.com'
THEHIVE_API_KEY = 'YOUR_API_KEY'

# Read alert
alert_file = open(sys.argv[1])
alert_json = json.loads(alert_file.read())
alert_file.close()

# Map Wazuh severity to TheHive severity
wazuh_level = alert_json.get('rule', {}).get('level', 0)
if wazuh_level >= 12:
    severity = 3  # High
elif wazuh_level >= 7:
    severity = 2  # Medium
else:
    severity = 1  # Low

# Create TheHive alert
thehive_alert = {
    'title': alert_json.get('rule', {}).get('description', 'Wazuh Alert'),
    'description': json.dumps(alert_json, indent=2),
    'type': 'wazuh',
    'source': 'wazuh',
    'sourceRef': str(alert_json.get('id', '')),
    'severity': severity,
    'date': int(datetime.now().timestamp() * 1000),
    'tags': alert_json.get('rule', {}).get('groups', []),
    'artifacts': []
}

# Add source IP if available
src_ip = alert_json.get('data', {}).get('srcip')
if src_ip:
    thehive_alert['artifacts'].append({
        'dataType': 'ip',
        'data': src_ip,
        'message': 'Source IP from Wazuh alert'
    })

# Send to TheHive
headers = {
    'Authorization': f'Bearer {THEHIVE_API_KEY}',
    'Content-Type': 'application/json'
}
response = requests.post(
    f'{THEHIVE_URL}/api/alert',
    headers=headers,
    json=thehive_alert
)

sys.exit(0 if response.status_code == 201 else 1)
```

### SIEM Integration (Splunk, Elasticsearch)

Forward alerts to external SIEM:

```xml
<!-- /var/ossec/etc/ossec.conf -->
<syslog_output>
  <server>splunk.example.com</server>
  <port>514</port>
  <format>json</format>
  <level>7</level>
</syslog_output>
```

## Custom Rules and Decoders

Create custom rules and decoders to parse and alert on application-specific logs.

### Understanding Decoders

Decoders extract fields from log messages:

```xml
<!-- /var/ossec/etc/decoders/local_decoder.xml -->
<!-- Custom decoders for application logs -->

<!-- Base decoder for custom application -->
<decoder name="myapp">
  <!-- Match log format: [TIMESTAMP] [LEVEL] [MODULE] Message -->
  <prematch>^\[\d{4}-\d{2}-\d{2}</prematch>
</decoder>

<!-- Child decoder to extract fields -->
<decoder name="myapp-fields">
  <parent>myapp</parent>
  <!-- Extract timestamp, level, module, and message -->
  <regex>^\[(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})\] \[(\w+)\] \[(\w+)\] (.+)$</regex>
  <order>timestamp,level,module,message</order>
</decoder>

<!-- Decoder for JSON application logs -->
<decoder name="myapp-json">
  <prematch>^{"timestamp":</prematch>
  <plugin_decoder>JSON_Decoder</plugin_decoder>
</decoder>

<!-- Decoder for nginx JSON access logs -->
<decoder name="nginx-json-access">
  <prematch>^{"time_local":</prematch>
  <plugin_decoder>JSON_Decoder</plugin_decoder>
</decoder>

<!-- Decoder for authentication failures in custom app -->
<decoder name="myapp-auth-failure">
  <parent>myapp</parent>
  <prematch>Authentication failed</prematch>
  <regex>Authentication failed for user '(\S+)' from (\S+)</regex>
  <order>user,srcip</order>
</decoder>

<!-- Decoder for SQL injection attempts -->
<decoder name="myapp-sqli">
  <parent>myapp</parent>
  <prematch>SQL injection</prematch>
  <regex>SQL injection detected from (\S+): (.+)$</regex>
  <order>srcip,payload</order>
</decoder>
```

### Creating Custom Rules

Custom rules trigger alerts based on decoded log data:

```xml
<!-- /var/ossec/etc/rules/local_rules.xml -->
<!-- Custom rules for security monitoring -->

<!-- Rule group for custom application -->
<group name="myapp,">

  <!-- Base rule for application logs -->
  <rule id="100001" level="0">
    <decoded_as>myapp</decoded_as>
    <description>MyApp log message</description>
  </rule>

  <!-- Authentication failure -->
  <rule id="100002" level="5">
    <if_sid>100001</if_sid>
    <match>Authentication failed</match>
    <description>MyApp: Authentication failure</description>
    <group>authentication_failed,</group>
  </rule>

  <!-- Multiple authentication failures (brute force) -->
  <rule id="100003" level="10" frequency="5" timeframe="120">
    <if_matched_sid>100002</if_matched_sid>
    <same_source_ip />
    <description>MyApp: Multiple authentication failures from same source</description>
    <mitre>
      <id>T1110</id>
    </mitre>
    <group>authentication_failures,brute_force,</group>
  </rule>

  <!-- SQL injection detection -->
  <rule id="100004" level="12">
    <if_sid>100001</if_sid>
    <match>SQL injection</match>
    <description>MyApp: SQL injection attempt detected</description>
    <mitre>
      <id>T1190</id>
    </mitre>
    <group>attack,sql_injection,</group>
  </rule>

  <!-- Privilege escalation attempt -->
  <rule id="100005" level="14">
    <if_sid>100001</if_sid>
    <match>Unauthorized admin access</match>
    <description>MyApp: Unauthorized privilege escalation attempt</description>
    <mitre>
      <id>T1068</id>
    </mitre>
    <group>attack,privilege_escalation,</group>
  </rule>

  <!-- Application error -->
  <rule id="100006" level="3">
    <if_sid>100001</if_sid>
    <field name="level">ERROR</field>
    <description>MyApp: Application error</description>
    <group>application_error,</group>
  </rule>

  <!-- Critical application error -->
  <rule id="100007" level="8">
    <if_sid>100001</if_sid>
    <field name="level">CRITICAL</field>
    <description>MyApp: Critical application error</description>
    <group>application_error,critical,</group>
  </rule>

  <!-- Sensitive data access -->
  <rule id="100008" level="7">
    <if_sid>100001</if_sid>
    <match>Accessed sensitive data:</match>
    <description>MyApp: Sensitive data accessed</description>
    <group>gdpr_iv_32.2,data_access,</group>
  </rule>

  <!-- Data export detected -->
  <rule id="100009" level="9">
    <if_sid>100001</if_sid>
    <match>Data export initiated</match>
    <description>MyApp: Data export operation detected</description>
    <group>gdpr_iv_33.1,data_export,</group>
  </rule>

</group>

<!-- Rules for web application firewall integration -->
<group name="waf,">

  <!-- WAF block event -->
  <rule id="100100" level="6">
    <decoded_as>nginx-json-access</decoded_as>
    <field name="status">^403$</field>
    <description>WAF: Request blocked</description>
    <group>web,access_denied,</group>
  </rule>

  <!-- Multiple WAF blocks from same IP -->
  <rule id="100101" level="10" frequency="10" timeframe="60">
    <if_matched_sid>100100</if_matched_sid>
    <same_source_ip />
    <description>WAF: Multiple blocked requests from same source (potential attack)</description>
    <group>web,attack,</group>
  </rule>

</group>

<!-- Rules for container security -->
<group name="docker,">

  <!-- Privileged container started -->
  <rule id="100200" level="10">
    <if_sid>87924</if_sid>
    <match>privileged</match>
    <description>Docker: Privileged container started</description>
    <group>container_security,</group>
  </rule>

  <!-- Container with host network -->
  <rule id="100201" level="8">
    <if_sid>87924</if_sid>
    <match>network_mode.*host</match>
    <description>Docker: Container started with host network</description>
    <group>container_security,</group>
  </rule>

</group>
```

### Testing Custom Rules

Test your rules using the `wazuh-logtest` utility:

```bash
# Start the log test utility
sudo /var/ossec/bin/wazuh-logtest

# Paste log samples to test decoding and rules
# Example input:
[2025-01-15 10:30:45] [ERROR] [AUTH] Authentication failed for user 'admin' from 192.168.1.50

# Expected output shows the matched decoder and rule
```

### Rule Syntax Reference

```xml
<!-- Rule structure reference -->
<rule id="UNIQUE_ID" level="SEVERITY">
  <!-- Parent rule (for composite rules) -->
  <if_sid>PARENT_RULE_ID</if_sid>

  <!-- Match decoded fields -->
  <field name="FIELD_NAME">REGEX_PATTERN</field>

  <!-- Match raw log content -->
  <match>STRING_OR_REGEX</match>
  <regex>PCRE2_REGEX</regex>

  <!-- Correlation options -->
  <frequency>COUNT</frequency>
  <timeframe>SECONDS</timeframe>
  <same_source_ip />
  <same_user />
  <different_srcip />

  <!-- Alert information -->
  <description>Alert description</description>

  <!-- MITRE ATT&CK mapping -->
  <mitre>
    <id>TECHNIQUE_ID</id>
  </mitre>

  <!-- Compliance mapping -->
  <group>pci_dss_10.6.1,gdpr_iv_32.2,</group>
</rule>
```

## Alerting Configuration

Configure how alerts are generated, stored, and distributed.

### Email Alerts

Configure email notifications for critical alerts:

```xml
<!-- /var/ossec/etc/ossec.conf -->
<global>
  <email_notification>yes</email_notification>
  <smtp_server>smtp.example.com</smtp_server>
  <email_from>wazuh@example.com</email_from>
  <email_to>security-team@example.com</email_to>
  <email_maxperhour>100</email_maxperhour>
</global>

<alerts>
  <!-- Minimum level for logging -->
  <log_alert_level>3</log_alert_level>
  <!-- Minimum level for email alerts -->
  <email_alert_level>10</email_alert_level>
</alerts>

<!-- Granular email configuration -->
<email_alerts>
  <email_to>critical-alerts@example.com</email_to>
  <level>14</level>
  <do_not_delay />
</email_alerts>

<email_alerts>
  <email_to>security@example.com</email_to>
  <group>authentication_failed</group>
</email_alerts>
```

### Active Response Configuration

Configure automated responses to security events:

```xml
<!-- /var/ossec/etc/ossec.conf -->

<!-- Define response commands -->
<command>
  <name>firewall-drop</name>
  <executable>firewall-drop</executable>
  <timeout_allowed>yes</timeout_allowed>
</command>

<command>
  <name>disable-account</name>
  <executable>disable-account</executable>
  <timeout_allowed>yes</timeout_allowed>
</command>

<command>
  <name>custom-block</name>
  <executable>custom-block.sh</executable>
  <timeout_allowed>yes</timeout_allowed>
</command>

<!-- Configure active responses -->

<!-- Block IP after brute force SSH -->
<active-response>
  <command>firewall-drop</command>
  <location>local</location>
  <rules_id>5763</rules_id>
  <timeout>3600</timeout>
</active-response>

<!-- Block IP after multiple web attacks -->
<active-response>
  <command>firewall-drop</command>
  <location>local</location>
  <rules_id>31151,31152,31153</rules_id>
  <timeout>1800</timeout>
</active-response>

<!-- Disable account after multiple sudo failures -->
<active-response>
  <command>disable-account</command>
  <location>local</location>
  <rules_id>5401,5402</rules_id>
  <timeout>7200</timeout>
</active-response>

<!-- Execute custom script on specific rule -->
<active-response>
  <command>custom-block</command>
  <location>server</location>
  <rules_id>100004</rules_id>
  <timeout>0</timeout>
</active-response>
```

Custom active response script example:

```bash
#!/bin/bash
# /var/ossec/active-response/bin/custom-block.sh
# Custom active response script for advanced blocking

LOCAL=`dirname $0`;
cd $LOCAL
cd ../

PWD=`pwd`
ACTION=$1
USER=$2
IP=$3
ALERTID=$4
RULEID=$5
AGENT=$6

# Log the action
echo "`date` - $ACTION $IP - Rule $RULEID" >> /var/ossec/logs/active-responses.log

# Add to blocklist
if [ "$ACTION" = "add" ]; then
    # Add IP to firewall block
    /usr/sbin/iptables -I INPUT -s $IP -j DROP
    /usr/sbin/iptables -I OUTPUT -d $IP -j DROP

    # Add to permanent blocklist
    echo "$IP # Blocked by Wazuh - Rule $RULEID - $(date)" >> /etc/blocklist.txt

    # Send notification
    curl -X POST "https://hooks.slack.com/services/YOUR/WEBHOOK" \
        -H "Content-Type: application/json" \
        -d "{\"text\":\"Blocked IP: $IP (Rule: $RULEID)\"}"
fi

# Remove from blocklist
if [ "$ACTION" = "delete" ]; then
    /usr/sbin/iptables -D INPUT -s $IP -j DROP
    /usr/sbin/iptables -D OUTPUT -d $IP -j DROP
fi

exit 0
```

### Alert Enrichment

Enhance alerts with additional context:

```xml
<!-- /var/ossec/etc/rules/local_rules.xml -->
<!-- Rules with GeoIP and enrichment -->

<rule id="100300" level="10">
  <if_sid>5763</if_sid>
  <geoip_src>!US,CA,GB</geoip_src>
  <description>SSH brute force from foreign country</description>
  <group>authentication_failures,brute_force,foreign_access,</group>
</rule>
```

## Best Practices and Maintenance

### Performance Tuning

```xml
<!-- /var/ossec/etc/ossec.conf -->

<!-- Tune analysis thread count based on CPU cores -->
<global>
  <max_output_size>20M</max_output_size>
</global>

<!-- Optimize remote connection handling -->
<remote>
  <connection>secure</connection>
  <port>1514</port>
  <protocol>tcp</protocol>
  <queue_size>131072</queue_size>
  <rids_closing_time>5s</rids_closing_time>
</remote>

<!-- Tune analysis engine -->
<analysisd>
  <queue_size>262144</queue_size>
  <rlimit_nofile>458752</rlimit_nofile>
  <min_rotate_interval>600</min_rotate_interval>
</analysisd>
```

### Log Rotation

```bash
# /etc/logrotate.d/wazuh
# Log rotation configuration for Wazuh

/var/ossec/logs/alerts/*.log
/var/ossec/logs/archives/*.log
/var/ossec/logs/ossec.log {
    daily
    rotate 30
    compress
    delaycompress
    missingok
    notifempty
    create 0640 root wazuh
    sharedscripts
    postrotate
        /var/ossec/bin/wazuh-control reload > /dev/null 2>&1 || true
    endscript
}
```

### Backup Configuration

```bash
#!/bin/bash
# /usr/local/bin/wazuh-backup.sh
# Backup Wazuh configuration and data

BACKUP_DIR="/backup/wazuh/$(date +%Y%m%d)"
mkdir -p $BACKUP_DIR

# Backup configuration
cp -r /var/ossec/etc $BACKUP_DIR/
cp -r /var/ossec/rules $BACKUP_DIR/

# Backup agent keys
cp /var/ossec/etc/client.keys $BACKUP_DIR/

# Backup custom decoders and rules
cp /var/ossec/etc/decoders/local_decoder.xml $BACKUP_DIR/
cp /var/ossec/etc/rules/local_rules.xml $BACKUP_DIR/

# Compress backup
tar -czvf $BACKUP_DIR.tar.gz $BACKUP_DIR
rm -rf $BACKUP_DIR

# Cleanup old backups (keep 30 days)
find /backup/wazuh -name "*.tar.gz" -mtime +30 -delete
```

### Health Monitoring Script

```bash
#!/bin/bash
# /usr/local/bin/wazuh-health-check.sh
# Health monitoring script for Wazuh components

check_service() {
    local service=$1
    if systemctl is-active --quiet $service; then
        echo "[OK] $service is running"
        return 0
    else
        echo "[FAIL] $service is not running"
        return 1
    fi
}

check_indexer() {
    local response=$(curl -s -k -u admin:admin https://localhost:9200/_cluster/health)
    local status=$(echo $response | jq -r '.status')

    if [ "$status" = "green" ] || [ "$status" = "yellow" ]; then
        echo "[OK] Wazuh indexer cluster status: $status"
        return 0
    else
        echo "[FAIL] Wazuh indexer cluster status: $status"
        return 1
    fi
}

check_agents() {
    local total=$(/var/ossec/bin/agent_control -l | grep -c "ID:")
    local active=$(/var/ossec/bin/agent_control -l | grep -c "Active")

    echo "[INFO] Total agents: $total, Active: $active"

    if [ $active -lt $total ]; then
        echo "[WARN] Some agents are not active"
        return 1
    fi
    return 0
}

# Run checks
echo "=== Wazuh Health Check ==="
echo "Date: $(date)"
echo ""

check_service wazuh-manager
check_service wazuh-indexer
check_service wazuh-dashboard
check_service filebeat

echo ""
check_indexer

echo ""
check_agents
```

## Monitoring Wazuh with OneUptime

While Wazuh provides comprehensive security monitoring for your infrastructure, it's equally important to ensure the Wazuh platform itself remains operational and performing optimally. OneUptime offers a robust solution for monitoring the availability and performance of your Wazuh deployment.

### Why Monitor Your Security Platform

Your security monitoring infrastructure is critical to maintaining visibility into threats across your environment. If Wazuh experiences downtime or performance degradation, security events may go undetected. OneUptime can help you:

- **Monitor component availability**: Track the uptime of Wazuh indexer, server, and dashboard
- **Set up intelligent alerting**: Receive notifications through multiple channels when issues arise
- **Track performance metrics**: Monitor resource utilization and response times
- **Establish baselines**: Understand normal operation patterns to detect anomalies

### Setting Up OneUptime Monitoring

Configure OneUptime to monitor your Wazuh endpoints:

1. **Dashboard availability**: Monitor the Wazuh dashboard HTTPS endpoint
2. **API health**: Check the Wazuh API endpoint at port 55000
3. **Indexer connectivity**: Verify the indexer REST API is responding
4. **Agent enrollment**: Ensure the enrollment service is accessible

With OneUptime's incident management capabilities, you can create automated workflows that trigger when Wazuh components become unavailable, ensuring your security team is immediately notified of any issues affecting your security monitoring capabilities.

Visit [OneUptime](https://oneuptime.com) to learn more about comprehensive infrastructure monitoring and how it can complement your Wazuh security deployment.

## Conclusion

This guide covered the complete installation and configuration of Wazuh on Ubuntu, including:

- Understanding Wazuh architecture and components
- Installing and configuring the Wazuh indexer, server, and dashboard
- Deploying agents across various operating systems
- Configuring file integrity monitoring for change detection
- Enabling vulnerability detection across your infrastructure
- Setting up compliance monitoring for PCI-DSS, GDPR, and other frameworks
- Integrating with third-party tools like Slack, PagerDuty, and TheHive
- Creating custom rules and decoders for application-specific monitoring
- Configuring alerting and active responses

Wazuh provides a powerful, open-source security platform that scales from small deployments to enterprise environments. Regular updates, active community support, and extensive documentation make it an excellent choice for organizations seeking comprehensive security monitoring without licensing costs.

Remember to keep your Wazuh installation updated, regularly review and tune your rules, and continuously adapt your security monitoring to address emerging threats and changing compliance requirements.
